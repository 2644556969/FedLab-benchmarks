{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import models\n",
    "\n",
    "sys.path.append(\"../../../FedLab/\")\n",
    "\n",
    "from fedlab.utils.dataset import functional as dataF\n",
    "from fedlab.utils import SerializationTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedlab.utils.dataset import CIFAR100Partitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "x = {'x':2, 'y': 1}\n",
    "for key in sorted(x.keys()):\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.66666666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = CIFAR10(root=\"../../../data/CIFAR10/\", train=True, \n",
    "                   download=True, \n",
    "                   transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset,\n",
    "            batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs, targets in train_loader:\n",
    "    tmp1 = targets.reshape(-1).long()\n",
    "    tmp2 = list(targets.size())[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.reshape(-1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mdl_params(model_list, n_par=None):\n",
    "    if n_par is None:\n",
    "        exp_mdl = model_list[0]\n",
    "        n_par = 0\n",
    "        for name, param in exp_mdl.named_parameters():\n",
    "            n_par += len(param.data.reshape(-1))\n",
    "\n",
    "    param_mat = np.zeros((len(model_list), n_par)).astype('float32')\n",
    "    for i, mdl in enumerate(model_list):\n",
    "        idx = 0\n",
    "        for name, param in mdl.named_parameters():\n",
    "            temp = param.data.cpu().numpy().reshape(-1)\n",
    "            param_mat[i, idx:idx + len(temp)] = temp\n",
    "            idx += len(temp)\n",
    "    return np.copy(param_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Cifar10Net('CIFAR10Net')\n",
    "local_par_list = None\n",
    "for param in model.parameters():\n",
    "    if not isinstance(local_par_list, torch.Tensor):\n",
    "        # Initially nothing to concatenate\n",
    "        local_par_list = param.reshape(-1)\n",
    "    else:\n",
    "        local_par_list = torch.cat((local_par_list, param.reshape(-1)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clnt = 100\n",
    "n_par = len(get_mdl_params([model])[0])\n",
    "\n",
    "local_param_list = np.zeros((n_clnt, n_par)).astype('float32')\n",
    "init_par_list = get_mdl_params([model], n_par)[0]\n",
    "clnt_params_list = np.ones(n_clnt).astype('float32').reshape(-1, 1) * init_par_list.reshape(1,\n",
    "                                                                                            -1)  # n_clnt X n_par\n",
    "clnt_models = list(range(n_clnt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 797962)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_param_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(797962,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_par_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 797962)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clnt_params_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(n_clnt).astype('float32').reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_param_list_curr = torch.tensor(local_param_list[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_param_list_curr.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'client_003_local_params'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_pattern = \"client_{cid:03d}_local_params\"\n",
    "file_pattern.format(cid=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator(object):\n",
    "    \"\"\"Deal with the mapping relation between client id in FL system and process rank in communication.\n",
    "    Note\n",
    "        Server Manager creates a Coordinator following:\n",
    "        1. init network connection.\n",
    "        2. client send local group info (the number of client simulating in local) to server.\n",
    "        4. server receive all info and init a server Coordinator.\n",
    "    Args:\n",
    "        setup_dict (dict): A dict like {rank:client_num ...}, representing the map relation between process rank and client id.\n",
    "        mode (str, optional): “GLOBAL” and \"LOCAL\". Coordinator will map client id to (rank, global id) or (rank, local id) according to mode. For example, client id 51 is in a machine which has 1 manager and serial trainer simulating 10 clients. LOCAL id means the index of its 10 clients. Therefore, global id 51 will be mapped into local id 1 (depending on setting).\n",
    "    \"\"\"\n",
    "    def __init__(self, setup_dict, mode='LOCAL') -> None:\n",
    "        self.map = setup_dict\n",
    "        self.mode = mode\n",
    "\n",
    "    def map_id(self, id):\n",
    "        \"\"\"a map function from client id to (rank,local id)\n",
    "        \n",
    "        Args:\n",
    "            id (int): client id\n",
    "        Returns:\n",
    "            rank, id : rank in distributed group and local id.\n",
    "        \"\"\"\n",
    "        m_id = id\n",
    "        for rank, num in self.map.items():\n",
    "            if m_id >= num:\n",
    "                m_id -= num\n",
    "            else:\n",
    "                local_id = m_id\n",
    "                global_id = id\n",
    "                ret_id = local_id if self.mode == 'LOCAL' else global_id\n",
    "                return rank, ret_id\n",
    "\n",
    "    def map_id_list(self, id_list):\n",
    "        \"\"\"a map function from id_list to dict{rank:local id}\n",
    "            This can be very useful in Scale modules.\n",
    "        Args:\n",
    "            id_list (list(int)): a list of client id.\n",
    "        Returns:\n",
    "            map_dict (dict): contains process rank and its relative local client ids.\n",
    "        \"\"\"\n",
    "        map_dict = {}\n",
    "        for id in id_list:\n",
    "            rank, id = self.map_id(id)\n",
    "            if rank in map_dict.keys():\n",
    "                map_dict[rank].append(id)\n",
    "            else:\n",
    "                map_dict[rank] = [id]\n",
    "        return map_dict\n",
    "\n",
    "    def switch(self):\n",
    "        if self.mode == 'GLOBAL':\n",
    "            self.mode = 'LOCAL'\n",
    "        elif self.mode == 'LOCAL':\n",
    "            self.mode = 'GLOBAL'\n",
    "        else:\n",
    "            raise ValueError(\"Invalid Map Mode {}\".format(self.mode))\n",
    "\n",
    "    @property\n",
    "    def total(self):\n",
    "        return int(sum(self.map.values()))\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"Coordinator map information: {} \\nMap mode: {} \\nTotal: {}\".format(\n",
    "            self.map, self.mode, self.total)\n",
    "\n",
    "    def __call__(self, info, *args, **kwds):\n",
    "        if isinstance(info, int):\n",
    "            return self.map_id(info)\n",
    "        if isinstance(info, list):\n",
    "            return self.map_id_list(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# cid: 0 to num_clients-1\n",
    "num_clients = 10\n",
    "for rank in range(1, 11):\n",
    "    print(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_client_id_map = {i:10 for i in range(1,11)}\n",
    "coordinator = Coordinator(rank_client_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [0, 1], 2: [1], 3: [0, 1, 2]}\n"
     ]
    }
   ],
   "source": [
    "id_list = [0, 1, 11, 20, 21, 22]\n",
    "num_clients_per_rank = 10\n",
    "res = coordinator.map_id_list(id_list)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_to_global(local_client_id, rank, num_clients_per_rank=10):\n",
    "    return (rank - 1) * num_clients_per_rank + local_client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "11\n",
      "20\n",
      "21\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "for rank in res:\n",
    "    for local_client_id in res[rank]:\n",
    "        print(local_to_global(local_client_id, rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = SerializationTool.serialize_model(model)\n",
    "params2 = SerializationTool.serialize_model(model)\n",
    "params3 = params1.data\n",
    "params4 = params1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0535,  0.0145,  0.0168,  ..., -0.0213,  0.0006,  0.0269])\n",
      "tensor([-0.0535,  0.0145,  0.0168,  ..., -0.0213,  0.0006,  0.0269])\n",
      "tensor([-0.0535,  0.0145,  0.0168,  ..., -0.0213,  0.0006,  0.0269])\n"
     ]
    }
   ],
   "source": [
    "print(params1)\n",
    "print(params2)\n",
    "print(params3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params1.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False, True, False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params1 is params2, params1 is params3, params1 is params4, params1.data is params3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> False\n",
      "<class 'torch.Tensor'> False\n",
      "<class 'torch.Tensor'> False\n",
      "<class 'torch.Tensor'> False\n"
     ]
    }
   ],
   "source": [
    "print(type(params1), params1.requires_grad)\n",
    "print(type(params2), params2.requires_grad)\n",
    "print(type(params3), params3.requires_grad)\n",
    "print(type(params4), params4.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_tensor = torch.zeros(params1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_torch]",
   "language": "python",
   "name": "conda-env-tf_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
