File: /home/liangsiqi/FedDyn/utils_dataset.py
File duration: 283.722s (12.41%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|from utils_libs import *
     2|         0|            0|            0|  0.00%|
     3|         0|            0|            0|  0.00%|class DatasetObject:
     4|         1|  3.57628e-06|  3.57628e-06|  0.00%|    def __init__(self, dataset, n_client, rule, unbalanced_sgm=0, rule_arg=''):
     5|         1|  5.00679e-06|  5.00679e-06|  0.00%|        self.dataset  = dataset
     6|         1|  2.38419e-06|  2.38419e-06|  0.00%|        self.n_client = n_client
     7|         1|  1.90735e-06|  1.90735e-06|  0.00%|        self.rule     = rule
     8|         1|  2.14577e-06|  2.14577e-06|  0.00%|        self.rule_arg = rule_arg
     9|         1|  2.38419e-06|  2.38419e-06|  0.00%|        rule_arg_str  = rule_arg if isinstance(rule_arg, str) else '%.3f' % rule_arg
    10|         1|  3.57628e-06|  3.57628e-06|  0.00%|        self.name = "%s_%d_%s_%s" %(self.dataset, self.n_client, self.rule, rule_arg_str)
    11|         1|  2.14577e-06|  2.14577e-06|  0.00%|        self.name += '_%f' %unbalanced_sgm if unbalanced_sgm!=0 else ''
    12|         1|  2.14577e-06|  2.14577e-06|  0.00%|        self.unbalanced_sgm = unbalanced_sgm
    13|         1|  1.90735e-06|  1.90735e-06|  0.00%|        self.data_path = 'Data'
    14|         1|   1.7643e-05|   1.7643e-05|  0.00%|        self.set_data()
(call)|         1|     0.404331|     0.404331|  0.02%|# /home/liangsiqi/FedDyn/utils_dataset.py:16 set_data
    15|         0|            0|            0|  0.00%|
    16|         1|   1.5974e-05|   1.5974e-05|  0.00%|    def set_data(self):
    17|         0|            0|            0|  0.00%|        # Prepare data if not ready
    18|         1|  1.83582e-05|  1.83582e-05|  0.00%|        if not os.path.exists('%s/%s' %(self.data_path, self.name)):
(call)|         1|  1.83582e-05|  1.83582e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/genericpath.py:16 exists
    19|         0|            0|            0|  0.00%|            # Get Raw data
    20|         0|            0|            0|  0.00%|            if self.dataset == 'mnist':
    21|         0|            0|            0|  0.00%|                transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
    22|         0|            0|            0|  0.00%|                trnset = torchvision.datasets.MNIST(root='%s/Raw' %self.data_path,
    23|         0|            0|            0|  0.00%|                                                    train=True , download=True, transform=transform)
    24|         0|            0|            0|  0.00%|                tstset = torchvision.datasets.MNIST(root='%s/Raw' %self.data_path,
    25|         0|            0|            0|  0.00%|                                                    train=False, download=True, transform=transform)
    26|         0|            0|            0|  0.00%|
    27|         0|            0|            0|  0.00%|                trn_load = torch.utils.data.DataLoader(trnset, batch_size=60000, shuffle=False, num_workers=1)
    28|         0|            0|            0|  0.00%|                tst_load = torch.utils.data.DataLoader(tstset, batch_size=10000, shuffle=False, num_workers=1)
    29|         0|            0|            0|  0.00%|                self.channels = 1; self.width = 28; self.height = 28; self.n_cls = 10;
    30|         0|            0|            0|  0.00%|
    31|         0|            0|            0|  0.00%|            if self.dataset == 'CIFAR10':
    32|         0|            0|            0|  0.00%|                transform = transforms.Compose([transforms.ToTensor(),
    33|         0|            0|            0|  0.00%|                                                transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])])
    34|         0|            0|            0|  0.00%|
    35|         0|            0|            0|  0.00%|                trnset = torchvision.datasets.CIFAR10(root='%s/Raw' %self.data_path,
    36|         0|            0|            0|  0.00%|                                                      train=True , download=True, transform=transform)
    37|         0|            0|            0|  0.00%|                tstset = torchvision.datasets.CIFAR10(root='%s/Raw' %self.data_path,
    38|         0|            0|            0|  0.00%|                                                      train=False, download=True, transform=transform)
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|                trn_load = torch.utils.data.DataLoader(trnset, batch_size=50000, shuffle=False, num_workers=1)
    41|         0|            0|            0|  0.00%|                tst_load = torch.utils.data.DataLoader(tstset, batch_size=10000, shuffle=False, num_workers=1)
    42|         0|            0|            0|  0.00%|                self.channels = 3; self.width = 32; self.height = 32; self.n_cls = 10;
    43|         0|            0|            0|  0.00%|
    44|         0|            0|            0|  0.00%|            if self.dataset == 'CIFAR100':
    45|         0|            0|            0|  0.00%|                print(self.dataset)
    46|         0|            0|            0|  0.00%|                # mean and std are validated here: https://gist.github.com/weiaicunzai/e623931921efefd4c331622c344d8151
    47|         0|            0|            0|  0.00%|                transform = transforms.Compose([transforms.ToTensor(),
    48|         0|            0|            0|  0.00%|                                                transforms.Normalize(mean=[0.5071, 0.4867, 0.4408],
    49|         0|            0|            0|  0.00%|                                                                     std=[0.2675, 0.2565, 0.2761])])
    50|         0|            0|            0|  0.00%|                trnset = torchvision.datasets.CIFAR100(root='%s/Raw' %self.data_path,
    51|         0|            0|            0|  0.00%|                                                      train=True , download=True, transform=transform)
    52|         0|            0|            0|  0.00%|                tstset = torchvision.datasets.CIFAR100(root='%s/Raw' %self.data_path,
    53|         0|            0|            0|  0.00%|                                                      train=False, download=True, transform=transform)
    54|         0|            0|            0|  0.00%|                trn_load = torch.utils.data.DataLoader(trnset, batch_size=50000, shuffle=False, num_workers=0)
    55|         0|            0|            0|  0.00%|                tst_load = torch.utils.data.DataLoader(tstset, batch_size=10000, shuffle=False, num_workers=0)
    56|         0|            0|            0|  0.00%|                self.channels = 3; self.width = 32; self.height = 32; self.n_cls = 100;
    57|         0|            0|            0|  0.00%|
    58|         0|            0|            0|  0.00%|            if self.dataset != 'emnist':
    59|         0|            0|            0|  0.00%|                trn_itr = trn_load.__iter__(); tst_itr = tst_load.__iter__()
    60|         0|            0|            0|  0.00%|                # labels are of shape (n_data,)
    61|         0|            0|            0|  0.00%|                trn_x, trn_y = trn_itr.__next__()
    62|         0|            0|            0|  0.00%|                tst_x, tst_y = tst_itr.__next__()
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|                trn_x = trn_x.numpy(); trn_y = trn_y.numpy().reshape(-1,1)
    65|         0|            0|            0|  0.00%|                tst_x = tst_x.numpy(); tst_y = tst_y.numpy().reshape(-1,1)
    66|         0|            0|            0|  0.00%|
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|            if self.dataset == 'emnist':
    69|         0|            0|            0|  0.00%|                emnist = io.loadmat(self.data_path + "/Raw/matlab/emnist-letters.mat")
    70|         0|            0|            0|  0.00%|                # load training dataset
    71|         0|            0|            0|  0.00%|                x_train = emnist["dataset"][0][0][0][0][0][0]
    72|         0|            0|            0|  0.00%|                x_train = x_train.astype(np.float32)
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|                # load training labels
    75|         0|            0|            0|  0.00%|                y_train = emnist["dataset"][0][0][0][0][0][1] - 1 # make first class 0
    76|         0|            0|            0|  0.00%|
    77|         0|            0|            0|  0.00%|                # take first 10 classes of letters
    78|         0|            0|            0|  0.00%|                trn_idx = np.where(y_train < 10)[0]
    79|         0|            0|            0|  0.00%|
    80|         0|            0|            0|  0.00%|                y_train = y_train[trn_idx]
    81|         0|            0|            0|  0.00%|                x_train = x_train[trn_idx]
    82|         0|            0|            0|  0.00%|
    83|         0|            0|            0|  0.00%|                mean_x = np.mean(x_train)
    84|         0|            0|            0|  0.00%|                std_x = np.std(x_train)
    85|         0|            0|            0|  0.00%|
    86|         0|            0|            0|  0.00%|                # load test dataset
    87|         0|            0|            0|  0.00%|                x_test = emnist["dataset"][0][0][1][0][0][0]
    88|         0|            0|            0|  0.00%|                x_test = x_test.astype(np.float32)
    89|         0|            0|            0|  0.00%|
    90|         0|            0|            0|  0.00%|                # load test labels
    91|         0|            0|            0|  0.00%|                y_test = emnist["dataset"][0][0][1][0][0][1] - 1 # make first class 0
    92|         0|            0|            0|  0.00%|
    93|         0|            0|            0|  0.00%|                tst_idx = np.where(y_test < 10)[0]
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|                y_test = y_test[tst_idx]
    96|         0|            0|            0|  0.00%|                x_test = x_test[tst_idx]
    97|         0|            0|            0|  0.00%|
    98|         0|            0|            0|  0.00%|                x_train = x_train.reshape((-1, 1, 28, 28))
    99|         0|            0|            0|  0.00%|                x_test  = x_test.reshape((-1, 1, 28, 28))
   100|         0|            0|            0|  0.00%|
   101|         0|            0|            0|  0.00%|                # normalise train and test features
   102|         0|            0|            0|  0.00%|
   103|         0|            0|            0|  0.00%|                trn_x = (x_train - mean_x) / std_x
   104|         0|            0|            0|  0.00%|                trn_y = y_train
   105|         0|            0|            0|  0.00%|
   106|         0|            0|            0|  0.00%|                tst_x = (x_test  - mean_x) / std_x
   107|         0|            0|            0|  0.00%|                tst_y = y_test
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|                self.channels = 1; self.width = 28; self.height = 28; self.n_cls = 10;
   110|         0|            0|            0|  0.00%|
   111|         0|            0|            0|  0.00%|            # Shuffle Data
   112|         0|            0|            0|  0.00%|            rand_perm = np.random.permutation(len(trn_y))
   113|         0|            0|            0|  0.00%|            trn_x = trn_x[rand_perm]
   114|         0|            0|            0|  0.00%|            trn_y = trn_y[rand_perm]
   115|         0|            0|            0|  0.00%|
   116|         0|            0|            0|  0.00%|            self.trn_x = trn_x
   117|         0|            0|            0|  0.00%|            self.trn_y = trn_y
   118|         0|            0|            0|  0.00%|            self.tst_x = tst_x
   119|         0|            0|            0|  0.00%|            self.tst_y = tst_y
   120|         0|            0|            0|  0.00%|
   121|         0|            0|            0|  0.00%|
   122|         0|            0|            0|  0.00%|            ###
   123|         0|            0|            0|  0.00%|            n_data_per_clnt = int((len(trn_y)) / self.n_client)
   124|         0|            0|            0|  0.00%|            if self.unbalanced_sgm != 0:
   125|         0|            0|            0|  0.00%|                # Draw from lognormal distribution
   126|         0|            0|            0|  0.00%|                clnt_data_list = (np.random.lognormal(mean=np.log(n_data_per_clnt), sigma=self.unbalanced_sgm, size=self.n_client))
   127|         0|            0|            0|  0.00%|                clnt_data_list = (clnt_data_list/np.sum(clnt_data_list)*len(trn_y)).astype(int)
   128|         0|            0|            0|  0.00%|                diff = np.sum(clnt_data_list) - len(trn_y)
   129|         0|            0|            0|  0.00%|
   130|         0|            0|            0|  0.00%|                # Add/Subtract the excess number starting from first client
   131|         0|            0|            0|  0.00%|                if diff!= 0:
   132|         0|            0|            0|  0.00%|                    for clnt_i in range(self.n_client):
   133|         0|            0|            0|  0.00%|                        if clnt_data_list[clnt_i] > diff:
   134|         0|            0|            0|  0.00%|                            clnt_data_list[clnt_i] -= diff
   135|         0|            0|            0|  0.00%|                            break
   136|         0|            0|            0|  0.00%|            else:
   137|         0|            0|            0|  0.00%|                clnt_data_list = (np.ones(self.n_client) * n_data_per_clnt).astype(int)
   138|         0|            0|            0|  0.00%|            ###
   139|         0|            0|            0|  0.00%|
   140|         0|            0|            0|  0.00%|            if self.rule == 'Dirichlet':
   141|         0|            0|            0|  0.00%|                cls_priors   = np.random.dirichlet(alpha=[self.rule_arg]*self.n_cls,size=self.n_client)
   142|         0|            0|            0|  0.00%|                prior_cumsum = np.cumsum(cls_priors, axis=1)
   143|         0|            0|            0|  0.00%|                idx_list = [np.where(trn_y==i)[0] for i in range(self.n_cls)]
   144|         0|            0|            0|  0.00%|                cls_amount = [len(idx_list[i]) for i in range(self.n_cls)]
   145|         0|            0|            0|  0.00%|
   146|         0|            0|            0|  0.00%|                clnt_x = [ np.zeros((clnt_data_list[clnt__], self.channels, self.height, self.width)).astype(np.float32) for clnt__ in range(self.n_client) ]
   147|         0|            0|            0|  0.00%|                clnt_y = [ np.zeros((clnt_data_list[clnt__], 1)).astype(np.int64) for clnt__ in range(self.n_client) ]
   148|         0|            0|            0|  0.00%|
   149|         0|            0|            0|  0.00%|                while(np.sum(clnt_data_list)!=0):
   150|         0|            0|            0|  0.00%|                    curr_clnt = np.random.randint(self.n_client)
   151|         0|            0|            0|  0.00%|                    # If current node is full resample a client
   152|         0|            0|            0|  0.00%|                    print('Remaining Data: %d' %np.sum(clnt_data_list))
   153|         0|            0|            0|  0.00%|                    if clnt_data_list[curr_clnt] <= 0:
   154|         0|            0|            0|  0.00%|                        continue
   155|         0|            0|            0|  0.00%|                    clnt_data_list[curr_clnt] -= 1
   156|         0|            0|            0|  0.00%|                    curr_prior = prior_cumsum[curr_clnt]
   157|         0|            0|            0|  0.00%|                    while True:
   158|         0|            0|            0|  0.00%|                        cls_label = np.argmax(np.random.uniform() <= curr_prior)
   159|         0|            0|            0|  0.00%|                        # Redraw class label if trn_y is out of that class
   160|         0|            0|            0|  0.00%|                        if cls_amount[cls_label] <= 0:
   161|         0|            0|            0|  0.00%|                            continue
   162|         0|            0|            0|  0.00%|                        cls_amount[cls_label] -= 1
   163|         0|            0|            0|  0.00%|                        clnt_x[curr_clnt][clnt_data_list[curr_clnt]] = trn_x[idx_list[cls_label][cls_amount[cls_label]]]
   164|         0|            0|            0|  0.00%|                        clnt_y[curr_clnt][clnt_data_list[curr_clnt]] = trn_y[idx_list[cls_label][cls_amount[cls_label]]]
   165|         0|            0|            0|  0.00%|
   166|         0|            0|            0|  0.00%|                        break
   167|         0|            0|            0|  0.00%|
   168|         0|            0|            0|  0.00%|                clnt_x = np.asarray(clnt_x)
   169|         0|            0|            0|  0.00%|                clnt_y = np.asarray(clnt_y)
   170|         0|            0|            0|  0.00%|
   171|         0|            0|            0|  0.00%|                cls_means = np.zeros((self.n_client, self.n_cls))
   172|         0|            0|            0|  0.00%|                for clnt in range(self.n_client):
   173|         0|            0|            0|  0.00%|                    for cls in range(self.n_cls):
   174|         0|            0|            0|  0.00%|                        cls_means[clnt,cls] = np.mean(clnt_y[clnt]==cls)
   175|         0|            0|            0|  0.00%|                prior_real_diff = np.abs(cls_means-cls_priors)
   176|         0|            0|            0|  0.00%|                print('--- Max deviation from prior: %.4f' %np.max(prior_real_diff))
   177|         0|            0|            0|  0.00%|                print('--- Min deviation from prior: %.4f' %np.min(prior_real_diff))
   178|         0|            0|            0|  0.00%|
   179|         0|            0|            0|  0.00%|            elif self.rule == 'iid' and self.dataset == 'CIFAR100' and self.unbalanced_sgm==0:
   180|         0|            0|            0|  0.00%|                assert len(trn_y)//100 % self.n_client == 0
   181|         0|            0|            0|  0.00%|                # Only have the number clients if it divides 500
   182|         0|            0|            0|  0.00%|                # Perfect IID partitions for cifar100 instead of shuffling
   183|         0|            0|            0|  0.00%|                idx = np.argsort(trn_y[:, 0])
   184|         0|            0|            0|  0.00%|                n_data_per_clnt = len(trn_y) // self.n_client
   185|         0|            0|            0|  0.00%|                # clnt_x dtype needs to be float32, the same as weights
   186|         0|            0|            0|  0.00%|                clnt_x = np.zeros((self.n_client, n_data_per_clnt, 3, 32, 32), dtype=np.float32)
   187|         0|            0|            0|  0.00%|                clnt_y = np.zeros((self.n_client, n_data_per_clnt, 1), dtype=np.float32)
   188|         0|            0|            0|  0.00%|                trn_x = trn_x[idx] # 50000*3*32*32
   189|         0|            0|            0|  0.00%|                trn_y = trn_y[idx]
   190|         0|            0|            0|  0.00%|                n_cls_sample_per_device = n_data_per_clnt // 100
   191|         0|            0|            0|  0.00%|                for i in range(self.n_client): # devices
   192|         0|            0|            0|  0.00%|                    for j in range(100): # class
   193|         0|            0|            0|  0.00%|                        clnt_x[i, n_cls_sample_per_device*j:n_cls_sample_per_device*(j+1), :, :, :] = trn_x[500*j+n_cls_sample_per_device*i:500*j+n_cls_sample_per_device*(i+1), :, :, :]
   194|         0|            0|            0|  0.00%|                        clnt_y[i, n_cls_sample_per_device*j:n_cls_sample_per_device*(j+1), :] = trn_y[500*j+n_cls_sample_per_device*i:500*j+n_cls_sample_per_device*(i+1), :]
   195|         0|            0|            0|  0.00%|
   196|         0|            0|            0|  0.00%|
   197|         0|            0|            0|  0.00%|            elif self.rule == 'iid':
   198|         0|            0|            0|  0.00%|
   199|         0|            0|            0|  0.00%|                clnt_x = [ np.zeros((clnt_data_list[clnt__], self.channels, self.height, self.width)).astype(np.float32) for clnt__ in range(self.n_client) ]
   200|         0|            0|            0|  0.00%|                clnt_y = [ np.zeros((clnt_data_list[clnt__], 1)).astype(np.int64) for clnt__ in range(self.n_client) ]
   201|         0|            0|            0|  0.00%|
   202|         0|            0|            0|  0.00%|                clnt_data_list_cum_sum = np.concatenate(([0], np.cumsum(clnt_data_list)))
   203|         0|            0|            0|  0.00%|                for clnt_idx_ in range(self.n_client):
   204|         0|            0|            0|  0.00%|                    clnt_x[clnt_idx_] = trn_x[clnt_data_list_cum_sum[clnt_idx_]:clnt_data_list_cum_sum[clnt_idx_+1]]
   205|         0|            0|            0|  0.00%|                    clnt_y[clnt_idx_] = trn_y[clnt_data_list_cum_sum[clnt_idx_]:clnt_data_list_cum_sum[clnt_idx_+1]]
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|
   208|         0|            0|            0|  0.00%|                clnt_x = np.asarray(clnt_x)
   209|         0|            0|            0|  0.00%|                clnt_y = np.asarray(clnt_y)
   210|         0|            0|            0|  0.00%|
   211|         0|            0|            0|  0.00%|
   212|         0|            0|            0|  0.00%|            self.clnt_x = clnt_x; self.clnt_y = clnt_y
   213|         0|            0|            0|  0.00%|
   214|         0|            0|            0|  0.00%|            self.tst_x  = tst_x;  self.tst_y  = tst_y
   215|         0|            0|            0|  0.00%|
   216|         0|            0|            0|  0.00%|            # Save data
   217|         0|            0|            0|  0.00%|            os.mkdir('%s/%s' %(self.data_path, self.name))
   218|         0|            0|            0|  0.00%|
   219|         0|            0|            0|  0.00%|            np.save('%s/%s/clnt_x.npy' %(self.data_path, self.name), clnt_x)
   220|         0|            0|            0|  0.00%|            np.save('%s/%s/clnt_y.npy' %(self.data_path, self.name), clnt_y)
   221|         0|            0|            0|  0.00%|
   222|         0|            0|            0|  0.00%|            np.save('%s/%s/tst_x.npy'  %(self.data_path, self.name),  tst_x)
   223|         0|            0|            0|  0.00%|            np.save('%s/%s/tst_y.npy'  %(self.data_path, self.name),  tst_y)
   224|         0|            0|            0|  0.00%|
   225|         0|            0|            0|  0.00%|        else:
   226|         1|  2.55108e-05|  2.55108e-05|  0.00%|            print("Data is already downloaded in the folder.")
   227|         1|  3.69549e-05|  3.69549e-05|  0.00%|            self.clnt_x = np.load('%s/%s/clnt_x.npy' %(self.data_path, self.name), allow_pickle=True)
(call)|         1|     0.267038|     0.267038|  0.01%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/numpy/lib/npyio.py:284 load
   228|         1|  3.40939e-05|  3.40939e-05|  0.00%|            self.clnt_y = np.load('%s/%s/clnt_y.npy' %(self.data_path, self.name), allow_pickle=True)
(call)|         1|   0.00354648|   0.00354648|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/numpy/lib/npyio.py:284 load
   229|         1|  1.12057e-05|  1.12057e-05|  0.00%|            self.n_client = len(self.clnt_x)
   230|         0|            0|            0|  0.00%|
   231|         1|  3.76701e-05|  3.76701e-05|  0.00%|            self.tst_x  = np.load('%s/%s/tst_x.npy'  %(self.data_path, self.name), allow_pickle=True)
(call)|         1|    0.0311108|    0.0311108|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/numpy/lib/npyio.py:284 load
   232|         1|  3.55244e-05|  3.55244e-05|  0.00%|            self.tst_y  = np.load('%s/%s/tst_y.npy'  %(self.data_path, self.name), allow_pickle=True)
(call)|         1|   0.00325108|   0.00325108|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/numpy/lib/npyio.py:284 load
   233|         0|            0|            0|  0.00%|
   234|         1|  1.04904e-05|  1.04904e-05|  0.00%|            if self.dataset == 'mnist':
   235|         0|            0|            0|  0.00%|                self.channels = 1; self.width = 28; self.height = 28; self.n_cls = 10;
   236|         1|  7.15256e-06|  7.15256e-06|  0.00%|            if self.dataset == 'CIFAR10':
   237|         1|  7.86781e-06|  7.86781e-06|  0.00%|                self.channels = 3; self.width = 32; self.height = 32; self.n_cls = 10;
   238|         1|  6.19888e-06|  6.19888e-06|  0.00%|            if self.dataset == 'CIFAR100':
   239|         0|            0|            0|  0.00%|                self.channels = 3; self.width = 32; self.height = 32; self.n_cls = 100;
   240|         1|  7.62939e-06|  7.62939e-06|  0.00%|            if self.dataset == 'fashion_mnist':
   241|         0|            0|            0|  0.00%|                self.channels = 1; self.width = 28; self.height = 28; self.n_cls = 10;
   242|         1|  6.19888e-06|  6.19888e-06|  0.00%|            if self.dataset == 'emnist':
   243|         0|            0|            0|  0.00%|                self.channels = 1; self.width = 28; self.height = 28; self.n_cls = 10;
   244|         0|            0|            0|  0.00%|
   245|         1|  2.19345e-05|  2.19345e-05|  0.00%|        print('Class frequencies:')
   246|         1|  6.67572e-06|  6.67572e-06|  0.00%|        count = 0
   247|       101|   0.00059104|  5.85188e-06|  0.00%|        for clnt in range(self.n_client):
   248|       300|   0.00242496|  8.08318e-06|  0.00%|            print("Client %3d: " %clnt +
   249|      1300|   0.00838113|  6.44702e-06|  0.00%|                  ', '.join(["%.3f" %np.mean(self.clnt_y[clnt]==cls) for cls in range(self.n_cls)]) +
(call)|      1000|    0.0851765|  8.51765e-05|  0.00%|# <__array_function__ internals>_0:2 mean
(call)|       100|    0.0921829|  0.000921829|  0.00%|# /home/liangsiqi/FedDyn/utils_dataset.py:249 <listcomp>
   250|       100|  0.000695944|  6.95944e-06|  0.00%|                  ', Amount:%d' %self.clnt_y[clnt].shape[0])
   251|       100|  0.000636578|  6.36578e-06|  0.00%|            count += self.clnt_y[clnt].shape[0]
   252|         0|            0|            0|  0.00%|
   253|         0|            0|            0|  0.00%|
   254|         1|  1.19209e-05|  1.19209e-05|  0.00%|        print('Total Amount:%d' %count)
   255|         1|  2.19345e-05|  2.19345e-05|  0.00%|        print('--------')
   256|         0|            0|            0|  0.00%|
   257|         3|  3.69549e-05|  1.23183e-05|  0.00%|        print("      Test: " +
   258|        13|   0.00012517|  9.62844e-06|  0.00%|              ', '.join(["%.3f" %np.mean(self.tst_y==cls) for cls in range(self.n_cls)]) +
(call)|        10|  0.000967741|  9.67741e-05|  0.00%|# <__array_function__ internals>_0:2 mean
(call)|         1|   0.00107265|   0.00107265|  0.00%|# /home/liangsiqi/FedDyn/utils_dataset.py:258 <listcomp>
   259|         1|  7.15256e-06|  7.15256e-06|  0.00%|              ', Amount:%d' %self.tst_y.shape[0])
   260|         0|            0|            0|  0.00%|
   
535|         0|            0|            0|  0.00%|class Dataset(torch.utils.data.Dataset):
   536|         0|            0|            0|  0.00%|
   537|      3060|   0.00729012|  2.38239e-06|  0.00%|    def __init__(self, data_x, data_y=True, train=False, dataset_name=''):
   538|      3060|   0.00790501|  2.58334e-06|  0.00%|        self.name = dataset_name
   539|      3060|   0.00613546|  2.00505e-06|  0.00%|        if self.name == 'mnist' or self.name == 'synt' or self.name == 'emnist':
   540|         0|            0|            0|  0.00%|            self.X_data = torch.tensor(data_x).float()
   541|         0|            0|            0|  0.00%|            self.y_data = data_y
   542|         0|            0|            0|  0.00%|            if not isinstance(data_y, bool):
   543|         0|            0|            0|  0.00%|                self.y_data = torch.tensor(data_y).float()
   544|         0|            0|            0|  0.00%|
   545|      3060|   0.00576234|  1.88312e-06|  0.00%|        elif self.name == 'CIFAR10' or self.name == 'CIFAR100':
   546|      3060|   0.00564218|  1.84385e-06|  0.00%|            self.train = train
   547|      3060|    0.0254614|  8.32073e-06|  0.00%|            self.transform = transforms.Compose([transforms.ToTensor()])
(call)|      3060|    0.0109906|  3.59171e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:55 __init__
   548|         0|            0|            0|  0.00%|
   549|      3060|   0.00560474|  1.83162e-06|  0.00%|            self.X_data = data_x
   550|      3060|   0.00554276|  1.81136e-06|  0.00%|            self.y_data = data_y
   551|      3060|   0.00712466|  2.32832e-06|  0.00%|            if not isinstance(data_y, bool):
   552|      3060|    0.0548646|  1.79296e-05|  0.00%|                self.y_data = data_y.astype('float32')
   553|         0|            0|            0|  0.00%|
   554|         0|            0|            0|  0.00%|        elif self.name == 'shakespeare':
   555|         0|            0|            0|  0.00%|
   556|         0|            0|            0|  0.00%|            self.X_data = data_x
   557|         0|            0|            0|  0.00%|            self.y_data = data_y
   558|         0|            0|            0|  0.00%|
   559|         0|            0|            0|  0.00%|            self.X_data = torch.tensor(self.X_data).long()
   560|         0|            0|            0|  0.00%|            if not isinstance(data_y, bool):
   561|         0|            0|            0|  0.00%|                self.y_data = torch.tensor(self.y_data).float()
   562|         0|            0|            0|  0.00%|
   563|         0|            0|            0|  0.00%|
   564|     12060|    0.0153923|  1.27631e-06|  0.00%|    def __len__(self):
   565|     12060|    0.0276396|  2.29184e-06|  0.00%|        return len(self.X_data)
   566|         0|            0|            0|  0.00%|
   567|   6300000|      12.1775|  1.93293e-06|  0.53%|    def __getitem__(self, idx):
   568|   6300000|      14.7108|  2.33505e-06|  0.64%|        if self.name == 'mnist' or self.name == 'synt' or self.name == 'emnist':
   569|         0|            0|            0|  0.00%|            X = self.X_data[idx, :]
   570|         0|            0|            0|  0.00%|            if isinstance(self.y_data, bool):
   571|         0|            0|            0|  0.00%|                return X
   572|         0|            0|            0|  0.00%|            else:
   573|         0|            0|            0|  0.00%|                y = self.y_data[idx]
   574|         0|            0|            0|  0.00%|                return X, y
   575|         0|            0|            0|  0.00%|
   576|   6300000|      12.7982|  2.03146e-06|  0.56%|        elif self.name == 'CIFAR10' or self.name == 'CIFAR100':
   577|   6300000|      13.9686|  2.21723e-06|  0.61%|            img = self.X_data[idx]
   578|   6300000|      12.4917|  1.98281e-06|  0.55%|            if self.train:
   579|   3750000|      27.8228|  7.41942e-06|  1.22%|                img = np.flip(img, axis=2).copy() if (np.random.rand() > .5) else img # Horizontal flip
(call)|   1875100|       134.27|  7.16071e-05|  5.87%|# <__array_function__ internals>_6:2 flip
   580|   3750000|      11.2003|  2.98676e-06|  0.49%|                if (np.random.rand() > .5):
   581|         0|            0|            0|  0.00%|                # Random cropping
   582|   1875450|       4.1113|  2.19217e-06|  0.18%|                    pad = 4
   583|   1875450|      15.2742|  8.14431e-06|  0.67%|                    extended_img = np.zeros((3,32 + pad *2, 32 + pad *2)).astype(np.float32)
   584|   1875450|      9.98929|  5.32634e-06|  0.44%|                    extended_img[:,pad:-pad,pad:-pad] = img
   585|   1875450|       30.494|  1.62596e-05|  1.33%|                    dim_1, dim_2 = np.random.randint(pad * 2 + 1, size=2)
(call)|   1875450|      127.219|  6.78336e-05|  5.56%|# <__array_function__ internals>_8:2 prod
   586|   1875450|      7.84183|  4.18131e-06|  0.34%|                    img = extended_img[:,dim_1:dim_1+32,dim_2:dim_2+32]
   587|   6300000|       34.938|  5.54571e-06|  1.53%|            img = np.moveaxis(img, 0, -1)
(call)|   6300000|      576.537|  9.15138e-05| 25.22%|# <__array_function__ internals>_7:2 moveaxis
   588|   6300000|      33.9056|  5.38184e-06|  1.48%|            img = self.transform(img)
(call)|   6300000|      369.733|  5.86877e-05| 16.17%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:58 __call__
   589|   6300000|      14.0553|    2.231e-06|  0.61%|            if isinstance(self.y_data, bool):
   590|         0|            0|            0|  0.00%|                return img
   591|         0|            0|            0|  0.00%|            else:
   592|   6300000|      15.0782|  2.39337e-06|  0.66%|                y = self.y_data[idx]
   593|   6300000|       12.677|  2.01223e-06|  0.55%|                return img, y
   594|         0|            0|            0|  0.00%|
   595|         0|            0|            0|  0.00%|        elif self.name == 'shakespeare':
   596|         0|            0|            0|  0.00%|            x = self.X_data[idx]
   597|         0|            0|            0|  0.00%|            y = self.y_data[idx]
   598|         0|            0|            0|  0.00%|            return x, y
   599|         0|            0|            0|  0.00%|


   File: /home/liangsiqi/FedDyn/utils_general.py
File duration: 52.5297s (2.30%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     9|         0|            0|            0|  0.00%|# --- Evaluate a NN model
    10|      1560|   0.00776672|  4.97867e-06|  0.00%|def get_acc_loss(data_x, data_y, model, dataset_name, w_decay = None):
    11|      1560|   0.00703573|  4.51008e-06|  0.00%|    acc_overall = 0; loss_overall = 0;
    12|      1560|    0.0185485|  1.18901e-05|  0.00%|    loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')
(call)|      1560|     0.825357|  0.000529075|  0.04%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/loss.py:1114 __init__
    13|      1560|   0.00964427|  6.18222e-06|  0.00%|    batch_size = min(6000, data_x.shape[0])
    14|      1560|   0.00659513|  4.22765e-06|  0.00%|    n_tst = data_x.shape[0]
    15|      1560|    0.0502656|  3.22215e-05|  0.00%|    tst_gen = data.DataLoader(Dataset(data_x, data_y, dataset_name=dataset_name), batch_size=batch_size, shuffle=False)
(call)|      3120|    0.0412672|  1.32267e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/typing.py:868 __new__
(call)|      1560|    0.0830414|  5.32317e-05|  0.00%|# /home/liangsiqi/FedDyn/utils_dataset.py:537 __init__
(call)|      1560|      1.34051|  0.000859302|  0.06%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:162 __init__
    16|      1560|    0.0261145|    1.674e-05|  0.00%|    model.eval(); model = model.to(device)
(call)|      1560|     0.862096|  0.000552625|  0.04%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1644 eval
(call)|      1560|      3.92473|   0.00251585|  0.17%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:752 to
    17|      1560|    0.0172057|  1.10293e-05|  0.00%|    with torch.no_grad():
(call)|      1560|    0.0187178|  1.19986e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/autograd/grad_mode.py:119 __init__
(call)|      1560|    0.0191121|  1.22514e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/autograd/grad_mode.py:124 __enter__
    18|      1560|    0.0119267|  7.64529e-06|  0.00%|        tst_gen_iter = tst_gen.__iter__()
(call)|      1560|     0.226807|  0.000145389|  0.01%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:346 __iter__
    19|      3390|    0.0337236|  9.94796e-06|  0.00%|        for i in range(int(np.ceil(n_tst/batch_size))):
(call)|      1560|     0.020853|  1.33673e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/autograd/grad_mode.py:128 __exit__
    20|      1830|    0.0242615|  1.32576e-05|  0.00%|            batch_x, batch_y = tst_gen_iter.__next__()
(call)|      1830|      436.008|     0.238256| 19.07%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:517 __next__
    21|      1830|      4.36621|   0.00238591|  0.19%|            batch_x = batch_x.to(device)
    22|      1830|     0.150208|  8.20807e-05|  0.01%|            batch_y = batch_y.to(device)
    23|      1830|    0.0235553|  1.28717e-05|  0.00%|            y_pred = model(batch_x)
(call)|      1830|      2.03024|   0.00110942|  0.09%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1045 _call_impl
    24|         0|            0|            0|  0.00%|
    25|      1830|       0.0595|  3.25136e-05|  0.00%|            loss = loss_fn(y_pred, batch_y.reshape(-1).long())
(call)|      1830|     0.214151|  0.000117022|  0.01%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1045 _call_impl
    26|      1830|      16.2376|   0.00887299|  0.71%|            loss_overall += loss.item()
    27|         0|            0|            0|  0.00%|            # Accuracy calculation
    28|      1830|      0.18616|  0.000101727|  0.01%|            y_pred = y_pred.cpu().numpy()
    29|      1830|    0.0226035|  1.23516e-05|  0.00%|            y_pred = np.argmax(y_pred, axis=1).reshape(-1)
(call)|      1830|     0.138142|  7.54874e-05|  0.01%|# <__array_function__ internals>_9:2 argmax
    30|      1830|    0.0496867|  2.71512e-05|  0.00%|            batch_y = batch_y.cpu().numpy().reshape(-1).astype(np.int32)
    31|      1830|    0.0293345|  1.60298e-05|  0.00%|            batch_correct = np.sum(y_pred == batch_y)
(call)|      1830|     0.127931|  6.99077e-05|  0.01%|# <__array_function__ internals>_10:2 sum
    32|      1830|   0.00581884|   3.1797e-06|  0.00%|            acc_overall += batch_correct
    33|         0|            0|            0|  0.00%|
    34|      1560|   0.00423574|  2.71522e-06|  0.00%|    loss_overall /= n_tst
    35|      1560|   0.00404048|  2.59005e-06|  0.00%|    if w_decay != None:
    36|         0|            0|            0|  0.00%|        # Add L2 loss
    37|      1500|    0.0171397|  1.14264e-05|  0.00%|        params = get_mdl_params([model], n_par=None)
(call)|      1500|       5.1294|    0.0034196|  0.22%|# /home/liangsiqi/FedDyn/utils_general.py:58 get_mdl_params
    38|      1500|     0.405875|  0.000270583|  0.02%|        loss_overall += w_decay/2 * np.sum(params * params)
(call)|      1500|      0.38618|  0.000257454|  0.02%|# <__array_function__ internals>_10:2 sum
    39|         0|            0|            0|  0.00%|
    40|      1560|    0.0116348|  7.45822e-06|  0.00%|    model.train()
(call)|      1560|     0.631079|  0.000404538|  0.03%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1622 train
    41|      1560|   0.00585318|  3.75204e-06|  0.00%|    return loss_overall, acc_overall / n_tst
    42|         0|            0|            0|  0.00%|
    43|         0|            0|            0|  0.00%|# --- Helper functions
    44|         0|            0|            0|  0.00%|
    45|        30|  0.000403881|  1.34627e-05|  0.00%|def set_client_from_params(mdl, params):
    46|        30|   0.00161791|  5.39303e-05|  0.00%|    dict_param = copy.deepcopy(dict(mdl.named_parameters()))
(call)|       330|    0.0174036|  5.27382e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1447 named_parameters
(call)|        30|    0.0496271|   0.00165424|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/copy.py:128 deepcopy
    47|        30|  9.29832e-05|  3.09944e-06|  0.00%|    idx = 0
    48|       330|    0.0019927|  6.03849e-06|  0.00%|    for name, param in mdl.named_parameters():
(call)|       330|    0.0232339|  7.04057e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1447 named_parameters
    49|       300|   0.00100589|  3.35296e-06|  0.00%|        weights = param.data
    50|       300|   0.00359082|  1.19694e-05|  0.00%|        length = len(weights.reshape(-1))
(call)|       300|   0.00340295|  1.13432e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/_tensor.py:585 __len__
    51|       300|     0.093339|   0.00031113|  0.00%|        dict_param[name].data.copy_(torch.tensor(params[idx:idx+length].reshape(weights.shape)).to(device))
    52|       300|   0.00137138|  4.57128e-06|  0.00%|        idx += length
    53|         0|            0|            0|  0.00%|
    54|        30|  0.000301123|  1.00374e-05|  0.00%|    mdl.load_state_dict(dict_param)
(call)|        30|    0.0546095|   0.00182032|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1354 load_state_dict
    55|        30|  7.03335e-05|  2.34445e-06|  0.00%|    return mdl
    56|         0|            0|            0|  0.00%|
    57|         0|            0|            0|  0.00%|
    58|      3002|   0.00728774|  2.42763e-06|  0.00%|def get_mdl_params(model_list, n_par=None):
    59|         0|            0|            0|  0.00%|
    60|      3002|   0.00738883|   2.4613e-06|  0.00%|    if n_par==None:
    61|      1501|    0.0031364|  2.08954e-06|  0.00%|        exp_mdl = model_list[0]
    62|      1501|   0.00278735|    1.857e-06|  0.00%|        n_par = 0
    63|     16511|      0.07336|   4.4431e-06|  0.00%|        for name, param in exp_mdl.named_parameters():
(call)|     16511|     0.815971|  4.94198e-05|  0.04%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1447 named_parameters
    64|     15010|     0.112617|  7.50278e-06|  0.00%|            n_par += len(param.data.reshape(-1))
(call)|     15010|     0.104457|  6.95917e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/_tensor.py:585 __len__
    65|         0|            0|            0|  0.00%|
    66|      3002|      1.94304|  0.000647249|  0.08%|    param_mat = np.zeros((len(model_list), n_par)).astype('float32')
    67|      6004|    0.0213108|  3.54943e-06|  0.00%|    for i, mdl in enumerate(model_list):
    68|      3002|   0.00626564|  2.08716e-06|  0.00%|        idx = 0
    69|     33022|     0.148998|  4.51207e-06|  0.01%|        for name, param in mdl.named_parameters():
(call)|     33022|      1.73136|  5.24305e-05|  0.08%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1447 named_parameters
    70|     30020|      2.09227|  6.96959e-05|  0.09%|            temp = param.data.cpu().numpy().reshape(-1)
    71|     30020|      1.11706|  3.72104e-05|  0.05%|            param_mat[i, idx:idx + len(temp)] = temp
    72|     30020|    0.0566587|  1.88737e-06|  0.00%|            idx += len(temp)
    73|      3002|    0.0212729|  7.08624e-06|  0.00%|    return np.copy(param_mat)
(call)|      3002|     0.762946|  0.000254146|  0.03%|# <__array_function__ internals>_2:2 copy
    74|         0|            0|            0|  0.00%|
    76|         0|            0|            0|  0.00%|
    77|      1500|   0.00582457|  3.88304e-06|  0.00%|def train_model(model, trn_x, trn_y, learning_rate, batch_size, epoch, print_per, weight_decay, dataset_name):
    78|      1500|   0.00633287|  4.22192e-06|  0.00%|    n_trn = trn_x.shape[0]
    79|      1500|    0.0382175|  2.54784e-05|  0.00%|    trn_gen = data.DataLoader(Dataset(trn_x, trn_y, train=True, dataset_name=dataset_name), batch_size=batch_size, shuffle=True)
(call)|      3000|    0.0294685|  9.82285e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/typing.py:868 __new__
(call)|      1500|    0.0592825|  3.95217e-05|  0.00%|# /home/liangsiqi/FedDyn/utils_dataset.py:537 __init__
(call)|      1500|     0.976701|  0.000651134|  0.04%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:162 __init__
    80|      1500|    0.0137098|  9.13986e-06|  0.00%|    loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')
(call)|      1500|     0.531192|  0.000354128|  0.02%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/loss.py:1114 __init__
    81|         0|            0|            0|  0.00%|
    82|      1500|    0.0156395|  1.04264e-05|  0.00%|    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
(call)|      1500|      1.34613|  0.000897417|  0.06%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/optim/sgd.py:56 __init__
    83|      1500|    0.0172467|  1.14978e-05|  0.00%|    model.train(); model = model.to(device)
(call)|      1500|     0.563015|  0.000375343|  0.02%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1622 train
(call)|      1500|      1.56392|   0.00104261|  0.07%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:752 to
    84|         0|            0|            0|  0.00%|
    85|      9000|    0.0297253|  3.30281e-06|  0.00%|    for e in range(epoch):
    86|         0|            0|            0|  0.00%|        # Training
    87|         0|            0|            0|  0.00%|
    88|      7500|     0.135108|  1.80144e-05|  0.01%|        trn_gen_iter = trn_gen.__iter__()
(call)|      7500|      1.21124|  0.000161499|  0.05%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:346 __iter__
    89|     82500|     0.394319|  4.77962e-06|  0.02%|        for i in range(int(np.ceil(n_trn/batch_size))):
    90|     75000|     0.935531|  1.24737e-05|  0.04%|            batch_x, batch_y = trn_gen_iter.__next__()
(call)|     75000|       1239.8|    0.0165306| 54.23%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:517 __next__
    91|     75000|      11.0118|  0.000146824|  0.48%|            batch_x = batch_x.to(device)
    92|     75000|      1.87313|   2.4975e-05|  0.08%|            batch_y = batch_y.to(device)
    93|         0|            0|            0|  0.00%|
    94|     75000|     0.976974|  1.30263e-05|  0.04%|            y_pred = model(batch_x)
(call)|     75000|       89.245|   0.00118993|  3.90%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1045 _call_impl
    95|     75000|      3.39428|  4.52571e-05|  0.15%|            loss = loss_fn(y_pred, batch_y.reshape(-1).long())
(call)|     75000|       8.9643|  0.000119524|  0.39%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1045 _call_impl
    96|     75000|      2.02268|  2.69691e-05|  0.09%|            loss = loss / list(batch_y.size())[0]
    97|         0|            0|            0|  0.00%|
    98|     75000|      0.63391|  8.45214e-06|  0.03%|            optimizer.zero_grad()
(call)|     75000|      42.3464|  0.000564619|  1.85%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/optim/optimizer.py:188 zero_grad
    99|     75000|     0.891578|  1.18877e-05|  0.04%|            loss.backward()
(call)|     75000|      98.4035|   0.00131205|  4.30%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/_tensor.py:205 backward
   100|     75000|      1.50122|  2.00162e-05|  0.07%|            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_norm) # Clip gradients
(call)|     75000|       172.73|   0.00230307|  7.56%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py:9 clip_grad_norm_
   101|     75000|     0.854552|   1.1394e-05|  0.04%|            optimizer.step()
(call)|     75000|      88.5644|   0.00118086|  3.87%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/optim/optimizer.py:83 wrapper
   102|         0|            0|            0|  0.00%|
   103|      7500|    0.0279224|  3.72299e-06|  0.00%|        if (e+1) % print_per == 0:
   104|      1500|    0.0527952|  3.51968e-05|  0.00%|            loss_trn, acc_trn = get_acc_loss(trn_x, trn_y, model, dataset_name, weight_decay)
(call)|      1500|      152.167|     0.101445|  6.66%|# /home/liangsiqi/FedDyn/utils_general.py:10 get_acc_loss
(call)|      1500|   0.00443125|  2.95417e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/sampler.py:224 __iter__
   105|      1500|    0.0463772|  3.09181e-05|  0.00%|            print("Epoch %3d, Training Accuracy: %.4f, Loss: %.4f" %(e+1, acc_trn, loss_trn))
   106|      1500|   0.00967526|  6.45018e-06|  0.00%|            model.train()
(call)|      1500|     0.605508|  0.000403672|  0.03%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1622 train
   107|         0|            0|            0|  0.00%|
   108|         0|            0|            0|  0.00%|    # Freeze model
   109|     16500|    0.0831194|  5.03754e-06|  0.00%|    for params in model.parameters():
(call)|     16500|     0.946082|  5.73383e-05|  0.04%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1423 parameters
   110|     15000|    0.0355949|    2.373e-06|  0.00%|        params.requires_grad = False
   111|      1500|   0.00933313|  6.22209e-06|  0.00%|    model.eval()
(call)|      1500|     0.592432|  0.000394955|  0.03%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1644 eval
   112|         0|            0|            0|  0.00%|
   113|      1500|   0.00337291|  2.24861e-06|  0.00%|    return model
   114|         0|            0|            0|  0.00%|
   

File: /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py
File duration: 35.9982s (1.57%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|r""""Contains definitions of the methods used by the _BaseDataLoaderIter to fetch
     2|         0|            0|            0|  0.00%|data from an iterable-style or map-style dataset. This logic is shared in both
     3|         0|            0|            0|  0.00%|single- and multi-processing data loading.
     4|         0|            0|            0|  0.00%|"""
     5|         0|            0|            0|  0.00%|
     6|         0|            0|            0|  0.00%|
     7|         0|            0|            0|  0.00%|class _BaseDatasetFetcher(object):
     8|      9060|     0.014858|  1.63996e-06|  0.00%|    def __init__(self, dataset, auto_collation, collate_fn, drop_last):
     9|      9060|    0.0187612|  2.07077e-06|  0.00%|        self.dataset = dataset
    10|      9060|     0.017184|  1.89669e-06|  0.00%|        self.auto_collation = auto_collation
    11|      9060|    0.0168116|  1.85559e-06|  0.00%|        self.collate_fn = collate_fn
    12|      9060|    0.0163698|  1.80682e-06|  0.00%|        self.drop_last = drop_last
    13|         0|            0|            0|  0.00%|
    14|         0|            0|            0|  0.00%|    def fetch(self, possibly_batched_index):
    15|         0|            0|            0|  0.00%|        raise NotImplementedError()
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|class _IterableDatasetFetcher(_BaseDatasetFetcher):
    19|         0|            0|            0|  0.00%|    def __init__(self, dataset, auto_collation, collate_fn, drop_last):
    20|         0|            0|            0|  0.00%|        super(_IterableDatasetFetcher, self).__init__(dataset, auto_collation, collate_fn, drop_last)
    21|         0|            0|            0|  0.00%|        self.dataset_iter = iter(dataset)
    22|         0|            0|            0|  0.00%|
    23|         0|            0|            0|  0.00%|    def fetch(self, possibly_batched_index):
    24|         0|            0|            0|  0.00%|        if self.auto_collation:
    25|         0|            0|            0|  0.00%|            data = []
    26|         0|            0|            0|  0.00%|            for _ in possibly_batched_index:
    27|         0|            0|            0|  0.00%|                try:
    28|         0|            0|            0|  0.00%|                    data.append(next(self.dataset_iter))
    29|         0|            0|            0|  0.00%|                except StopIteration:
    30|         0|            0|            0|  0.00%|                    break
    31|         0|            0|            0|  0.00%|            if len(data) == 0 or (self.drop_last and len(data) < len(possibly_batched_index)):
    32|         0|            0|            0|  0.00%|                raise StopIteration
    33|         0|            0|            0|  0.00%|        else:
    34|         0|            0|            0|  0.00%|            data = next(self.dataset_iter)
    35|         0|            0|            0|  0.00%|        return self.collate_fn(data)
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|
    38|         0|            0|            0|  0.00%|class _MapDatasetFetcher(_BaseDatasetFetcher):
    39|      9060|    0.0170157|  1.87811e-06|  0.00%|    def __init__(self, dataset, auto_collation, collate_fn, drop_last):
    40|      9060|     0.066802|  7.37329e-06|  0.00%|        super(_MapDatasetFetcher, self).__init__(dataset, auto_collation, collate_fn, drop_last)
(call)|      9060|    0.0839846|  9.26982e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:8 __init__
    41|         0|            0|            0|  0.00%|
    42|     76830|     0.169774|  2.20974e-06|  0.01%|    def fetch(self, possibly_batched_index):
    43|     76830|     0.180675|  2.35162e-06|  0.01%|        if self.auto_collation:
    44|   6530490|      34.7123|  5.31542e-06|  1.52%|            data = [self.dataset[idx] for idx in possibly_batched_index]
(call)|   6300000|      1491.29|  0.000236713| 65.23%|# /home/liangsiqi/FedDyn/utils_dataset.py:567 __getitem__
(call)|     76830|      1525.57|    0.0198564| 66.73%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:44 <listcomp>
    45|         0|            0|            0|  0.00%|        else:
    46|         0|            0|            0|  0.00%|            data = self.dataset[possibly_batched_index]
    47|     76830|     0.767645|  9.99148e-06|  0.03%|        return self.collate_fn(data)
(call)|     76830|      91.8196|    0.0011951|  4.02%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:43 default_collate



   
File: /home/liangsiqi/FedDyn/utils_methods.py
File duration: 8.40909s (0.37%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     6|         0|            0|            0|  0.00%|### Methods
     7|         1|  1.57356e-05|  1.57356e-05|  0.00%|def train_FedAvg(data_obj, act_prob ,learning_rate, batch_size, epoch, com_amount, print_per, weight_decay, model_func, init_model, save_period, lr_decay_per_round, rand_seed=0):
     8|         1|  1.38283e-05|  1.38283e-05|  0.00%|    method_name = 'FedAvg'
     9|         1|  1.09673e-05|  1.09673e-05|  0.00%|    n_clnt=data_obj.n_client
    10|         1|  1.07288e-05|  1.07288e-05|  0.00%|    clnt_x = data_obj.clnt_x; clnt_y=data_obj.clnt_y
    11|         0|            0|            0|  0.00%|
    12|         1|  0.000122786|  0.000122786|  0.00%|    cent_x = np.concatenate(clnt_x, axis=0)
(call)|         1|     0.126492|     0.126492|  0.01%|# <__array_function__ internals>_1:2 concatenate
    13|         1|  2.43187e-05|  2.43187e-05|  0.00%|    cent_y = np.concatenate(clnt_y, axis=0)
(call)|         1|   0.00015974|   0.00015974|  0.00%|# <__array_function__ internals>_1:2 concatenate
    14|         0|            0|            0|  0.00%|
    15|       103|  0.000192404|    1.868e-06|  0.00%|    weight_list = np.asarray([len(clnt_y[i]) for i in range(n_clnt)])
(call)|         1|  0.000162601|  0.000162601|  0.00%|# /home/liangsiqi/FedDyn/utils_methods.py:15 <listcomp>
(call)|         1|  2.81334e-05|  2.81334e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/numpy/core/_asarray.py:23 asarray
    16|         1|  9.53674e-06|  9.53674e-06|  0.00%|    weight_list = weight_list.reshape((n_clnt, 1))
    17|         0|            0|            0|  0.00%|
    18|         1|  1.71661e-05|  1.71661e-05|  0.00%|    if not os.path.exists('Output/%s/%s' %(data_obj.name, method_name)):
(call)|         1|  2.47955e-05|  2.47955e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/genericpath.py:16 exists
    19|         0|            0|            0|  0.00%|        os.mkdir('Output/%s/%s' %(data_obj.name, method_name))
    20|         0|            0|            0|  0.00%|
    21|         1|  7.39098e-06|  7.39098e-06|  0.00%|    n_save_instances = int(com_amount / save_period)
    22|         1|  1.21593e-05|  1.21593e-05|  0.00%|    fed_mdls_sel = list(range(n_save_instances)); fed_mdls_all = list(range(n_save_instances))
    23|         0|            0|            0|  0.00%|
    24|         1|  9.53674e-06|  9.53674e-06|  0.00%|    trn_perf_sel = np.zeros((com_amount, 2)); trn_perf_all = np.zeros((com_amount, 2))
    25|         1|   6.4373e-06|   6.4373e-06|  0.00%|    tst_perf_sel = np.zeros((com_amount, 2)); tst_perf_all = np.zeros((com_amount, 2))
    26|         1|  0.000140429|  0.000140429|  0.00%|    n_par = len(get_mdl_params([model_func()])[0])
(call)|         1|   0.00989199|   0.00989199|  0.00%|# fedavg_speed.py:29 <lambda>
(call)|         1|   0.00535679|   0.00535679|  0.00%|# /home/liangsiqi/FedDyn/utils_general.py:58 get_mdl_params
    27|         0|            0|            0|  0.00%|
    28|         1|  2.67029e-05|  2.67029e-05|  0.00%|    init_par_list=get_mdl_params([init_model], n_par)[0]
(call)|         1|   0.00257587|   0.00257587|  0.00%|# /home/liangsiqi/FedDyn/utils_general.py:58 get_mdl_params
    29|         1|    0.0555131|    0.0555131|  0.00%|    clnt_params_list=np.ones(n_clnt).astype('float32').reshape(-1, 1) * init_par_list.reshape(1, -1) # n_clnt X n_par
(call)|         1|  6.55651e-05|  6.55651e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/numpy/core/numeric.py:148 ones
    30|         1|  2.95639e-05|  2.95639e-05|  0.00%|    clnt_models = list(range(n_clnt))
    31|         0|            0|            0|  0.00%|
    32|         1|  3.50475e-05|  3.50475e-05|  0.00%|    avg_model = model_func().to(device)
(call)|         1|   0.00831723|   0.00831723|  0.00%|# fedavg_speed.py:29 <lambda>
(call)|         1|      2.69434|      2.69434|  0.12%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:752 to
    33|         1|  7.93934e-05|  7.93934e-05|  0.00%|    avg_model.load_state_dict(copy.deepcopy(dict(init_model.named_parameters())))
(call)|        11|  0.000520229|  4.72936e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1447 named_parameters
(call)|         1|   0.00136137|   0.00136137|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/copy.py:128 deepcopy
(call)|         1|   0.00222516|   0.00222516|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1354 load_state_dict
    34|         0|            0|            0|  0.00%|
    35|         1|  2.64645e-05|  2.64645e-05|  0.00%|    all_model = model_func().to(device)
(call)|         1|    0.0088141|    0.0088141|  0.00%|# fedavg_speed.py:29 <lambda>
(call)|         1|   0.00177789|   0.00177789|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:752 to
    36|         1|  7.55787e-05|  7.55787e-05|  0.00%|    all_model.load_state_dict(copy.deepcopy(dict(init_model.named_parameters())))
(call)|        11|  0.000569105|  5.17368e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1447 named_parameters
(call)|         1|   0.00095439|   0.00095439|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/copy.py:128 deepcopy
(call)|         1|   0.00214124|   0.00214124|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1354 load_state_dict
    37|         0|            0|            0|  0.00%|
    38|         1|  1.71661e-05|  1.71661e-05|  0.00%|    if os.path.exists('Output/%s/%s/%d_com_tst_perf_all.npy' %(data_obj.name, method_name, com_amount)):
(call)|         1|  3.74317e-05|  3.74317e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/genericpath.py:16 exists
    39|         0|            0|            0|  0.00%|        # Load performances and models...
    40|         0|            0|            0|  0.00%|        pass
    61|         0|            0|            0|  0.00%|    else:
    62|        16|  5.74589e-05|  3.59118e-06|  0.00%|        for i in range(com_amount):
    63|         0|            0|            0|  0.00%|
    64|        15|  5.07832e-05|  3.38554e-06|  0.00%|            inc_seed = 0
    65|         0|            0|            0|  0.00%|            while(True):
    66|         0|            0|            0|  0.00%|                # Fix randomness in client selection
    67|        15|  0.000236988|  1.57992e-05|  0.00%|                np.random.seed(i + rand_seed + inc_seed)
    68|        15|  0.000390768|  2.60512e-05|  0.00%|                act_list    = np.random.uniform(size=n_clnt)
    69|        15|  0.000156164|  1.04109e-05|  0.00%|                act_clients = act_list <= act_prob
    70|        15|  0.000208378|  1.38919e-05|  0.00%|                selected_clnts = np.sort(np.where(act_clients)[0])
(call)|        15|  0.000318289|  2.12193e-05|  0.00%|# <__array_function__ internals>_4:2 where
(call)|        15|  0.000738621|  4.92414e-05|  0.00%|# <__array_function__ internals>_5:2 sort
    71|        15|  5.03063e-05|  3.35375e-06|  0.00%|                inc_seed += 1
    72|        15|  5.34058e-05|  3.56038e-06|  0.00%|                if len(selected_clnts) != 0:
    73|        15|  4.81606e-05|   3.2107e-06|  0.00%|                    break
    74|      1545|   0.00221515|  1.43375e-06|  0.00%|            print('Selected Clients: %s' %(', '.join(['%2d' %item for item in selected_clnts])))
(call)|        15|   0.00191855|  0.000127904|  0.00%|# /home/liangsiqi/FedDyn/utils_methods.py:74 <listcomp>
    75|         0|            0|            0|  0.00%|
    76|      1515|    0.0122931|  8.11426e-06|  0.00%|            for clnt in selected_clnts:
    77|      1500|    0.0364487|  2.42991e-05|  0.00%|                print('---- Training client %d' %clnt)
    78|      1500|   0.00715947|  4.77298e-06|  0.00%|                trn_x = clnt_x[clnt]
    79|      1500|   0.00576639|  3.84426e-06|  0.00%|                trn_y = clnt_y[clnt]
    80|         0|            0|            0|  0.00%|
    81|      1500|    0.0986702|  6.57802e-05|  0.00%|                clnt_models[clnt] = model_func().to(device)
(call)|      1500|      12.6824|   0.00845491|  0.55%|# fedavg_speed.py:29 <lambda>
(call)|      1500|      2.65553|   0.00177035|  0.12%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:752 to
    82|      1500|     0.107065|  7.13766e-05|  0.00%|                clnt_models[clnt].load_state_dict(copy.deepcopy(dict(avg_model.named_parameters())))
(call)|     16500|     0.819379|  4.96593e-05|  0.04%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1447 named_parameters
(call)|      1500|       1.3828|  0.000921864|  0.06%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/copy.py:128 deepcopy
(call)|      1500|      2.28617|   0.00152411|  0.10%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1354 load_state_dict
    83|         0|            0|            0|  0.00%|
    84|     16500|     0.106417|   6.4495e-06|  0.00%|                for params in clnt_models[clnt].parameters():
(call)|     16500|     0.901086|  5.46112e-05|  0.04%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1423 parameters
    85|     15000|    0.0472648|  3.15099e-06|  0.00%|                    params.requires_grad = True
    86|      1500|    0.0887682|  5.91788e-05|  0.00%|                clnt_models[clnt] = train_model(clnt_models[clnt], trn_x, trn_y, learning_rate * (lr_decay_per_round ** i), batch_size, epoch, print_per, weight_decay, data_obj.dataset)
(call)|      1500|      1925.67|      1.28378| 84.23%|# /home/liangsiqi/FedDyn/utils_general.py:77 train_model
(call)|      1500|     0.027148|  1.80987e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/sampler.py:224 __iter__
    87|         0|            0|            0|  0.00%|
    88|      1500|     0.387578|  0.000258385|  0.02%|                clnt_params_list[clnt] = get_mdl_params([clnt_models[clnt]], n_par)[0]
(call)|      1500|      3.89085|    0.0025939|  0.17%|# /home/liangsiqi/FedDyn/utils_general.py:58 get_mdl_params
    89|         0|            0|            0|  0.00%|
    90|         0|            0|            0|  0.00%|            # Scale with weights
    91|        15|      4.13307|     0.275538|  0.18%|            avg_model = set_client_from_params(model_func(), np.sum(clnt_params_list[selected_clnts]*weight_list[selected_clnts]/np.sum(weight_list[selected_clnts]), axis = 0))
(call)|        15|     0.125069|   0.00833794|  0.01%|# fedavg_speed.py:29 <lambda>
(call)|        30|     0.997555|    0.0332518|  0.04%|# <__array_function__ internals>_10:2 sum
(call)|        15|     0.125155|   0.00834366|  0.01%|# /home/liangsiqi/FedDyn/utils_general.py:45 set_client_from_params
    92|        15|       3.3125|     0.220833|  0.14%|            all_model = set_client_from_params(model_func(), np.sum(clnt_params_list*weight_list/np.sum(weight_list), axis = 0))
(call)|        15|     0.140619|    0.0093746|  0.01%|# fedavg_speed.py:29 <lambda>
(call)|        30|     0.993831|    0.0331277|  0.04%|# <__array_function__ internals>_10:2 sum
(call)|        15|     0.126908|   0.00846054|  0.01%|# /home/liangsiqi/FedDyn/utils_general.py:45 set_client_from_params
    93|         0|            0|            0|  0.00%|
    94|         0|            0|            0|  0.00%|            ###
    95|        15|    0.0011518|  7.67867e-05|  0.00%|            loss_tst, acc_tst = get_acc_loss(data_obj.tst_x, data_obj.tst_y, avg_model, data_obj.dataset)
(call)|        15|      27.3888|      1.82592|  1.20%|# /home/liangsiqi/FedDyn/utils_general.py:10 get_acc_loss
(call)|        15|  5.00679e-05|  3.33786e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/sampler.py:224 __iter__
    96|        15|  0.000153303|  1.02202e-05|  0.00%|            tst_perf_sel[i] = [loss_tst, acc_tst]
    97|        15|  0.000453472|  3.02315e-05|  0.00%|            print("**** Communication sel %3d, Test Accuracy: %.4f, Loss: %.4f" %(i+1, acc_tst, loss_tst))
    98|         0|            0|            0|  0.00%|            ###
    99|        15|  0.000743389|  4.95593e-05|  0.00%|            loss_tst, acc_tst = get_acc_loss(cent_x, cent_y, avg_model, data_obj.dataset)
(call)|        15|      133.817|      8.92111|  5.85%|# /home/liangsiqi/FedDyn/utils_general.py:10 get_acc_loss
(call)|        15|  5.57899e-05|  3.71933e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/sampler.py:224 __iter__
   100|        15|  0.000139713|  9.31422e-06|  0.00%|            trn_perf_sel[i] = [loss_tst, acc_tst]
   101|        15|  0.000451803|  3.01202e-05|  0.00%|            print("**** Communication sel %3d, Cent Accuracy: %.4f, Loss: %.4f" %(i+1, acc_tst, loss_tst))
   102|         0|            0|            0|  0.00%|            ###
   103|        15|   0.00112987|  7.53244e-05|  0.00%|            loss_tst, acc_tst = get_acc_loss(data_obj.tst_x, data_obj.tst_y, all_model, data_obj.dataset)
(call)|        15|       26.672|      1.77814|  1.17%|# /home/liangsiqi/FedDyn/utils_general.py:10 get_acc_loss
(call)|        15|  4.93526e-05|  3.29018e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/sampler.py:224 __iter__
   104|        15|  0.000155687|  1.03792e-05|  0.00%|            tst_perf_all[i] = [loss_tst, acc_tst]
   105|        15|  0.000466824|  3.11216e-05|  0.00%|            print("**** Communication all %3d, Test Accuracy: %.4f, Loss: %.4f" %(i+1, acc_tst, loss_tst))
   106|         0|            0|            0|  0.00%|            ###
   107|        15|  0.000711441|  4.74294e-05|  0.00%|            loss_tst, acc_tst = get_acc_loss(cent_x, cent_y, all_model, data_obj.dataset)
(call)|        15|      133.776|       8.9184|  5.85%|# /home/liangsiqi/FedDyn/utils_general.py:10 get_acc_loss
(call)|        15|  4.79221e-05|  3.19481e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/sampler.py:224 __iter__
   108|        15|  0.000143528|  9.56853e-06|  0.00%|            trn_perf_all[i] = [loss_tst, acc_tst]
   109|        15|  0.000422239|  2.81493e-05|  0.00%|            print("**** Communication all %3d, Cent Accuracy: %.4f, Loss: %.4f" %(i+1, acc_tst, loss_tst))
   110|         0|            0|            0|  0.00%|
   111|        15|  5.76973e-05|  3.84649e-06|  0.00%|            
   133|        15|  4.95911e-05|  3.30607e-06|  0.00%|            if ((i+1) % save_period == 0):
   134|         0|            0|            0|  0.00%|                fed_mdls_sel[i//save_period] = avg_model
   135|         0|            0|            0|  0.00%|                fed_mdls_all[i//save_period] = all_model
   136|         0|            0|            0|  0.00%|
   137|         1|  3.57628e-06|  3.57628e-06|  0.00%|    return fed_mdls_sel, trn_perf_sel, tst_perf_sel, fed_mdls_all, trn_perf_all, tst_perf_all
   138|         0|            0|            0|  0.00%|
   139|         0|            0|            0|  0.00%|







File: /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py
File duration: 8.94006s (0.39%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
    43|         0|            0|            0|  0.00%|class _DatasetKind(object):
    44|         0|            0|            0|  0.00%|    Map = 0
    45|         0|            0|            0|  0.00%|    Iterable = 1
    46|         0|            0|            0|  0.00%|
    47|      9060|     0.019629|  2.16656e-06|  0.00%|    @staticmethod
    48|         0|            0|            0|  0.00%|    def create_fetcher(kind, dataset, auto_collation, collate_fn, drop_last):
    49|      9060|    0.0234792|  2.59153e-06|  0.00%|        if kind == _DatasetKind.Map:
    50|      9060|    0.0706356|  7.79642e-06|  0.00%|            return _utils.fetch._MapDatasetFetcher(dataset, auto_collation, collate_fn, drop_last)
(call)|      9060|     0.167802|  1.85212e-05|  0.01%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:39 __init__
    51|         0|            0|            0|  0.00%|        else:
    52|         0|            0|            0|  0.00%|            return _utils.fetch._IterableDatasetFetcher(dataset, auto_collation, collate_fn, drop_last)
    53|         0|            0|            0|  0.00%|
    54|         0|            0|            0|  0.00%|
    71|         0|            0|            0|  0.00%|class DataLoader(Generic[T_co]):
   151|         0|            0|            0|  0.00%|    dataset: Dataset[T_co]
   152|         0|            0|            0|  0.00%|    batch_size: Optional[int]
   153|         0|            0|            0|  0.00%|    num_workers: int
   154|         0|            0|            0|  0.00%|    pin_memory: bool
   155|         0|            0|            0|  0.00%|    drop_last: bool
   156|         0|            0|            0|  0.00%|    timeout: float
   157|         0|            0|            0|  0.00%|    sampler: Sampler
   158|         0|            0|            0|  0.00%|    prefetch_factor: int
   159|         0|            0|            0|  0.00%|    _iterator : Optional['_BaseDataLoaderIter']
   160|         0|            0|            0|  0.00%|    __initialized = False
   161|         0|            0|            0|  0.00%|
   162|      3060|    0.0117581|  3.84251e-06|  0.00%|    def __init__(self, dataset: Dataset[T_co], batch_size: Optional[int] = 1,
   163|         0|            0|            0|  0.00%|                 shuffle: bool = False, sampler: Optional[Sampler[int]] = None,
   164|         0|            0|            0|  0.00%|                 batch_sampler: Optional[Sampler[Sequence[int]]] = None,
   165|         0|            0|            0|  0.00%|                 num_workers: int = 0, collate_fn: Optional[_collate_fn_t] = None,
   166|         0|            0|            0|  0.00%|                 pin_memory: bool = False, drop_last: bool = False,
   167|         0|            0|            0|  0.00%|                 timeout: float = 0, worker_init_fn: Optional[_worker_init_fn_t] = None,
   168|         0|            0|            0|  0.00%|                 multiprocessing_context=None, generator=None,
   169|         0|            0|            0|  0.00%|                 *, prefetch_factor: int = 2,
   170|         0|            0|            0|  0.00%|                 persistent_workers: bool = False):
   171|      3060|     0.016196|  5.29281e-06|  0.00%|        torch._C._log_api_usage_once("python.data_loader")
   172|         0|            0|            0|  0.00%|
   173|      3060|   0.00775528|  2.53441e-06|  0.00%|        if num_workers < 0:
   174|         0|            0|            0|  0.00%|            raise ValueError('num_workers option should be non-negative; '
   175|         0|            0|            0|  0.00%|                             'use num_workers=0 to disable multiprocessing.')
   176|         0|            0|            0|  0.00%|
   177|      3060|   0.00659037|  2.15371e-06|  0.00%|        if timeout < 0:
   178|         0|            0|            0|  0.00%|            raise ValueError('timeout option should be non-negative')
   179|         0|            0|            0|  0.00%|
   180|      3060|    0.0069046|  2.25641e-06|  0.00%|        if num_workers == 0 and prefetch_factor != 2:
   181|         0|            0|            0|  0.00%|            raise ValueError('prefetch_factor option could only be specified in multiprocessing.'
   182|         0|            0|            0|  0.00%|                             'let num_workers > 0 to enable multiprocessing.')
   183|      3060|   0.00705576|   2.3058e-06|  0.00%|        assert prefetch_factor > 0
   184|         0|            0|            0|  0.00%|
   185|      3060|   0.00689173|   2.2522e-06|  0.00%|        if persistent_workers and num_workers == 0:
   186|         0|            0|            0|  0.00%|            raise ValueError('persistent_workers option needs num_workers > 0')
   187|         0|            0|            0|  0.00%|
   188|      3060|    0.0225582|  7.37196e-06|  0.00%|        self.dataset = dataset
(call)|      3060|    0.0234625|  7.66749e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   189|      3060|    0.0182703|  5.97067e-06|  0.00%|        self.num_workers = num_workers
(call)|      3060|    0.0158136|  5.16784e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   190|      3060|    0.0172708|  5.64405e-06|  0.00%|        self.prefetch_factor = prefetch_factor
(call)|      3060|    0.0145617|  4.75871e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   191|      3060|    0.0173745|  5.67795e-06|  0.00%|        self.pin_memory = pin_memory
(call)|      3060|    0.0146685|  4.79362e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   192|      3060|    0.0172811|   5.6474e-06|  0.00%|        self.timeout = timeout
(call)|      3060|     0.014514|  4.74313e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   193|      3060|    0.0190754|  6.23379e-06|  0.00%|        self.worker_init_fn = worker_init_fn
(call)|      3060|    0.0155506|   5.0819e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   194|      3060|    0.0177009|  5.78461e-06|  0.00%|        self.multiprocessing_context = multiprocessing_context
(call)|      3060|     0.071661|  2.34186e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   195|         0|            0|            0|  0.00%|
   200|      3060|    0.0256116|  8.36982e-06|  0.00%|        if isinstance(dataset, IterableDataset):
(call)|      3060|      1.19472|   0.00039043|  0.05%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/typing.py:1009 __instancecheck__
   201|         0|            0|            0|  0.00%|            self._dataset_kind = _DatasetKind.Iterable
   202|         0|            0|            0|  0.00%|            # NOTE [ Custom Samplers and IterableDataset 
   227|         0|            0|            0|  0.00%|            if shuffle is not False:
   228|         0|            0|            0|  0.00%|                raise ValueError(
   229|         0|            0|            0|  0.00%|                    "DataLoader with IterableDataset: expected unspecified "
   230|         0|            0|            0|  0.00%|                    "shuffle option, but got shuffle={}".format(shuffle))
   231|         0|            0|            0|  0.00%|            elif sampler is not None:
   232|         0|            0|            0|  0.00%|                # See NOTE [ Custom Samplers and IterableDataset ]
   233|         0|            0|            0|  0.00%|                raise ValueError(
   234|         0|            0|            0|  0.00%|                    "DataLoader with IterableDataset: expected unspecified "
   235|         0|            0|            0|  0.00%|                    "sampler option, but got sampler={}".format(sampler))
   236|         0|            0|            0|  0.00%|            elif batch_sampler is not None:
   237|         0|            0|            0|  0.00%|                # See NOTE [ Custom Samplers and IterableDataset ]
   238|         0|            0|            0|  0.00%|                raise ValueError(
   239|         0|            0|            0|  0.00%|                    "DataLoader with IterableDataset: expected unspecified "
   240|         0|            0|            0|  0.00%|                    "batch_sampler option, but got batch_sampler={}".format(batch_sampler))
   241|         0|            0|            0|  0.00%|        else:
   242|      3060|    0.0211699|  6.91827e-06|  0.00%|            self._dataset_kind = _DatasetKind.Map
(call)|      3060|    0.0175891|  5.74807e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   243|         0|            0|            0|  0.00%|
   244|      3060|   0.00690556|  2.25672e-06|  0.00%|        if sampler is not None and shuffle:
   245|         0|            0|            0|  0.00%|            raise ValueError('sampler option is mutually exclusive with '
   246|         0|            0|            0|  0.00%|                             'shuffle')
   247|         0|            0|            0|  0.00%|
   248|      3060|   0.00663805|   2.1693e-06|  0.00%|        if batch_sampler is not None:
   249|         0|            0|            0|  0.00%|            # auto_collation with custom batch_sampler
   250|         0|            0|            0|  0.00%|            if batch_size != 1 or shuffle or sampler is not None or drop_last:
   251|         0|            0|            0|  0.00%|                raise ValueError('batch_sampler option is mutually exclusive '
   252|         0|            0|            0|  0.00%|                                 'with batch_size, shuffle, sampler, and '
   253|         0|            0|            0|  0.00%|                                 'drop_last')
   254|         0|            0|            0|  0.00%|            batch_size = None
   255|         0|            0|            0|  0.00%|            drop_last = False
   256|      3060|   0.00642729|  2.10042e-06|  0.00%|        elif batch_size is None:
   257|         0|            0|            0|  0.00%|            # no auto_collation
   258|         0|            0|            0|  0.00%|            if drop_last:
   259|         0|            0|            0|  0.00%|                raise ValueError('batch_size=None option disables auto-batching '
   260|         0|            0|            0|  0.00%|                                 'and is mutually exclusive with drop_last')
   261|         0|            0|            0|  0.00%|
   262|      3060|   0.00712228|  2.32754e-06|  0.00%|        if sampler is None:  # give default samplers
   263|      3060|   0.00807595|   2.6392e-06|  0.00%|            if self._dataset_kind == _DatasetKind.Iterable:
   264|         0|            0|            0|  0.00%|                # See NOTE [ Custom Samplers and IterableDataset ]
   265|         0|            0|            0|  0.00%|                sampler = _InfiniteConstantSampler()
   266|         0|            0|            0|  0.00%|            else:  # map-style
   267|      3060|   0.00699139|  2.28477e-06|  0.00%|                if shuffle:
   268|         0|            0|            0|  0.00%|                    # Cannot statically verify that dataset is Sized
   269|         0|            0|            0|  0.00%|                    # Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]
   270|      1500|    0.0154555|  1.03037e-05|  0.00%|                    sampler = RandomSampler(dataset, generator=generator)  # type: ignore[arg-type]
(call)|      1500|    0.0120976|  8.06506e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/typing.py:868 __new__
(call)|      1500|    0.0559332|  3.72888e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/sampler.py:86 __init__
   271|         0|            0|            0|  0.00%|                else:
   272|      1560|    0.0205014|  1.31419e-05|  0.00%|                    sampler = SequentialSampler(dataset)  # type: ignore[arg-type]
(call)|      1560|    0.0175638|  1.12589e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/typing.py:868 __new__
(call)|      1560|   0.00682139|  4.37269e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/sampler.py:62 __init__
   273|         0|            0|            0|  0.00%|
   274|      3060|   0.00771022|  2.51968e-06|  0.00%|        if batch_size is not None and batch_sampler is None:
   275|         0|            0|            0|  0.00%|            # auto_collation without custom batch_sampler
   276|      3060|    0.0341527|   1.1161e-05|  0.00%|            batch_sampler = BatchSampler(sampler, batch_size, drop_last)
(call)|      3060|     0.026283|  8.58922e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/typing.py:868 __new__
(call)|      3060|    0.0448084|  1.46433e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/sampler.py:209 __init__
   277|         0|            0|            0|  0.00%|
   278|      3060|    0.0187459|  6.12611e-06|  0.00%|        self.batch_size = batch_size
(call)|      3060|    0.0161066|   5.2636e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   279|      3060|    0.0172441|  5.63533e-06|  0.00%|        self.drop_last = drop_last
(call)|      3060|    0.0147567|  4.82244e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   280|      3060|    0.0171015|  5.58873e-06|  0.00%|        self.sampler = sampler
(call)|      3060|    0.0144215|   4.7129e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   281|      3060|    0.0167482|  5.47326e-06|  0.00%|        self.batch_sampler = batch_sampler
(call)|      3060|    0.0142479|  4.65617e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   282|      3060|     0.016773|  5.48137e-06|  0.00%|        self.generator = generator
(call)|      3060|    0.0142515|  4.65734e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   283|         0|            0|            0|  0.00%|
   284|      3060|   0.00643921|  2.10432e-06|  0.00%|        if collate_fn is None:
   285|      3060|    0.0181444|  5.92953e-06|  0.00%|            if self._auto_collation:
(call)|      3060|   0.00905752|  2.95997e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:361 _auto_collation
   286|      3060|   0.00954652|  3.11978e-06|  0.00%|                collate_fn = _utils.collate.default_collate
   287|         0|            0|            0|  0.00%|            else:
   288|         0|            0|            0|  0.00%|                collate_fn = _utils.collate.default_convert
   289|         0|            0|            0|  0.00%|
   290|      3060|    0.0172443|   5.6354e-06|  0.00%|        self.collate_fn = collate_fn
(call)|      3060|    0.0145805|  4.76487e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   291|      3060|    0.0167358|  5.46921e-06|  0.00%|        self.persistent_workers = persistent_workers
(call)|      3060|    0.0143142|  4.67783e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   292|         0|            0|            0|  0.00%|
   293|      3060|    0.0169091|  5.52586e-06|  0.00%|        self.__initialized = True
(call)|      3060|    0.0144238|  4.71368e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   294|      3060|    0.0167589|  5.47677e-06|  0.00%|        self._IterableDataset_len_called = None  # See NOTE [ IterableDataset and __len__ ]
(call)|      3060|    0.0155239|  5.07317e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   295|         0|            0|            0|  0.00%|
   296|      3060|    0.0171309|  5.59832e-06|  0.00%|        self._iterator = None
(call)|      3060|    0.0150189|  4.90815e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   297|         0|            0|            0|  0.00%|
   298|      3060|    0.0222418|  7.26857e-06|  0.00%|        self.check_worker_number_rationality()
(call)|      3060|    0.0272567|  8.90743e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:406 check_worker_number_rationality
   299|         0|            0|            0|  0.00%|
   300|      9060|    0.0143588|  1.58485e-06|  0.00%|    def _get_iterator(self) -> '_BaseDataLoaderIter':
   301|      9060|       0.0191|  2.10816e-06|  0.00%|        if self.num_workers == 0:
   302|      9060|    0.0565276|  6.23925e-06|  0.00%|            return _SingleProcessDataLoaderIter(self)
(call)|      9060|      1.25555|  0.000138582|  0.05%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:551 __init__
   303|         0|            0|            0|  0.00%|        else:
   304|         0|            0|            0|  0.00%|            self.check_worker_number_rationality()
   305|         0|            0|            0|  0.00%|            return _MultiProcessingDataLoaderIter(self)
   333|         0|            0|            0|  0.00%|
   334|      3060|     0.015991|  5.22581e-06|  0.00%|        self.__multiprocessing_context = multiprocessing_context
(call)|      3060|    0.0149052|  4.87099e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:336 __setattr__
   335|         0|            0|            0|  0.00%|
   336|     58140|     0.085042|  1.46271e-06|  0.00%|    def __setattr__(self, attr, val):
   337|     58140|    0.0911031|  1.56696e-06|  0.00%|        if self.__initialized and attr in (
   338|         0|            0|            0|  0.00%|                'batch_size', 'batch_sampler', 'sampler', 'drop_last', 'dataset', 'persistent_workers'):
   339|         0|            0|            0|  0.00%|            raise ValueError('{} attribute should not be set after {} is '
   340|         0|            0|            0|  0.00%|                             'initialized'.format(attr, self.__class__.__name__))
   341|         0|            0|            0|  0.00%|
   342|     58140|     0.131248|  2.25744e-06|  0.01%|        super(DataLoader, self).__setattr__(attr, val)
(call)|      3060|     0.042979|  1.40454e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:311 multiprocessing_context
   343|         0|            0|            0|  0.00%|
   346|      9060|    0.0188775|  2.08361e-06|  0.00%|    def __iter__(self) -> '_BaseDataLoaderIter':
   352|      9060|    0.0186393|  2.05732e-06|  0.00%|        if self.persistent_workers and self.num_workers > 0:
   353|         0|            0|            0|  0.00%|            if self._iterator is None:
   354|         0|            0|            0|  0.00%|                self._iterator = self._get_iterator()
   355|         0|            0|            0|  0.00%|            else:
   356|         0|            0|            0|  0.00%|                self._iterator._reset(self)
   357|         0|            0|            0|  0.00%|            return self._iterator
   358|         0|            0|            0|  0.00%|        else:
   359|      9060|    0.0549955|  6.07015e-06|  0.00%|            return self._get_iterator()
(call)|      9060|      1.34554|  0.000148514|  0.06%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:300 _get_iterator
   360|         0|            0|            0|  0.00%|
   361|     21180|    0.0288379|  1.36156e-06|  0.00%|    @property
   362|         0|            0|            0|  0.00%|    def _auto_collation(self):
   363|     21180|    0.0356264|  1.68208e-06|  0.00%|        return self.batch_sampler is not None
   364|         0|            0|            0|  0.00%|
   365|      9060|    0.0131733|  1.45401e-06|  0.00%|    @property
   366|         0|            0|            0|  0.00%|    def _index_sampler(self):
   367|         0|            0|            0|  0.00%|        # The actual sampler used for generating indices for `_DatasetFetcher`
   368|         0|            0|            0|  0.00%|        # (see _utils/fetch.py) to read data at each time. This would be
   369|         0|            0|            0|  0.00%|        # `.batch_sampler` if in auto-collation mode, and `.sampler` otherwise.
   370|         0|            0|            0|  0.00%|        # We can't change `.sampler` and `.batch_sampler` attributes for BC
   371|         0|            0|            0|  0.00%|        # reasons.
   372|      9060|    0.0451188|     4.98e-06|  0.00%|        if self._auto_collation:
(call)|      9060|    0.0241034|  2.66042e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:361 _auto_collation
   373|      9060|     0.015759|   1.7394e-06|  0.00%|            return self.batch_sampler
   374|         0|            0|            0|  0.00%|        else:
   375|         0|            0|            0|  0.00%|            return self.sampler
   405|         0|            0|            0|  0.00%|
   406|      3060|   0.00836968|  2.73519e-06|  0.00%|    def check_worker_number_rationality(self):
   407|         0|            0|            0|  0.00%|        def _create_warning_msg(num_worker_suggest, num_worker_created, cpuset_checked):
   434|         0|            0|            0|  0.00%|
   435|         0|            0|            0|  0.00%|            suggested_max_worker_msg = ((
   436|         0|            0|            0|  0.00%|                "Our suggested max number of worker in current system is {}{}, which is smaller "
   437|         0|            0|            0|  0.00%|                "than what this DataLoader is going to create.").format(
   438|         0|            0|            0|  0.00%|                    num_worker_suggest,
   439|         0|            0|            0|  0.00%|                    ("" if cpuset_checked else " (`cpuset` is not taken into account)"))
   440|         0|            0|            0|  0.00%|            ) if num_worker_suggest is not None else (
   441|         0|            0|            0|  0.00%|                "DataLoader is not able to compute a suggested max number of worker in current system.")
   442|         0|            0|            0|  0.00%|
   443|         0|            0|            0|  0.00%|            warn_msg = (
   444|         0|            0|            0|  0.00%|                "This DataLoader will create {} worker processes in total. {} "
   445|         0|            0|            0|  0.00%|                "Please be aware that excessive worker creation might get DataLoader running slow or even freeze, "
   446|         0|            0|            0|  0.00%|                "lower the worker number to avoid potential slowness/freeze if necessary.").format(
   447|         0|            0|            0|  0.00%|                    num_worker_created,
   448|         0|            0|            0|  0.00%|                    suggested_max_worker_msg)
   449|         0|            0|            0|  0.00%|            return warn_msg
   450|         0|            0|            0|  0.00%|
   451|      3060|    0.0062108|  2.02967e-06|  0.00%|        if not self.num_workers or self.num_workers == 0:
   452|      3060|   0.00569701|  1.86177e-06|  0.00%|            return
   453|         0|            0|            0|  0.00%|
   454|         0|            0|            0|  0.00%|        # try to compute a suggested max number of worker based on system's resource
   455|         0|            0|            0|  0.00%|        max_num_worker_suggest = None
   456|         0|            0|            0|  0.00%|        cpuset_checked = False
   457|         0|            0|            0|  0.00%|        if hasattr(os, 'sched_getaffinity'):
   458|         0|            0|            0|  0.00%|            try:
   459|         0|            0|            0|  0.00%|                max_num_worker_suggest = len(os.sched_getaffinity(0))
   460|         0|            0|            0|  0.00%|                cpuset_checked = True
   461|         0|            0|            0|  0.00%|            except Exception:
   462|         0|            0|            0|  0.00%|                pass
   463|         0|            0|            0|  0.00%|        if max_num_worker_suggest is None:
   464|         0|            0|            0|  0.00%|            # os.cpu_count() could return Optional[int]
   465|         0|            0|            0|  0.00%|            # get cpu count first and check None in order to satify mypy check
   466|         0|            0|            0|  0.00%|            cpu_count = os.cpu_count()
   467|         0|            0|            0|  0.00%|            if cpu_count is not None:
   468|         0|            0|            0|  0.00%|                max_num_worker_suggest = cpu_count
   469|         0|            0|            0|  0.00%|
   470|         0|            0|            0|  0.00%|        if max_num_worker_suggest is None:
   471|         0|            0|            0|  0.00%|            warnings.warn(_create_warning_msg(
   472|         0|            0|            0|  0.00%|                max_num_worker_suggest,
   473|         0|            0|            0|  0.00%|                self.num_workers,
   474|         0|            0|            0|  0.00%|                cpuset_checked))
   475|         0|            0|            0|  0.00%|            return
   476|         0|            0|            0|  0.00%|
   477|         0|            0|            0|  0.00%|        if self.num_workers > max_num_worker_suggest:
   478|         0|            0|            0|  0.00%|            warnings.warn(_create_warning_msg(
   479|         0|            0|            0|  0.00%|                max_num_worker_suggest,
   480|         0|            0|            0|  0.00%|                self.num_workers,
   481|         0|            0|            0|  0.00%|                cpuset_checked))
   482|         0|            0|            0|  0.00%|
   483|         0|            0|            0|  0.00%|
   484|         0|            0|            0|  0.00%|class _BaseDataLoaderIter(object):
   485|      9060|    0.0208993|  2.30677e-06|  0.00%|    def __init__(self, loader: DataLoader) -> None:
   486|      9060|    0.0229325|  2.53118e-06|  0.00%|        self._dataset = loader.dataset
   487|      9060|    0.0197811|  2.18335e-06|  0.00%|        self._dataset_kind = loader._dataset_kind
   488|      9060|    0.0226278|  2.49755e-06|  0.00%|        self._IterableDataset_len_called = loader._IterableDataset_len_called
   489|      9060|    0.0576553|  6.36372e-06|  0.00%|        self._auto_collation = loader._auto_collation
(call)|      9060|    0.0313034|  3.45512e-06|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:361 _auto_collation
   490|      9060|    0.0192566|  2.12545e-06|  0.00%|        self._drop_last = loader.drop_last
   491|      9060|    0.0581012|  6.41293e-06|  0.00%|        self._index_sampler = loader._index_sampler
(call)|      9060|    0.0981545|  1.08338e-05|  0.00%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:365 _index_sampler
   492|      9060|    0.0187111|  2.06524e-06|  0.00%|        self._num_workers = loader.num_workers
   493|      9060|    0.0190482|  2.10245e-06|  0.00%|        self._prefetch_factor = loader.prefetch_factor
   494|      9060|     0.019491|  2.15132e-06|  0.00%|        self._pin_memory = loader.pin_memory and torch.cuda.is_available()
   495|      9060|    0.0176446|  1.94753e-06|  0.00%|        self._timeout = loader.timeout
   496|      9060|    0.0197158|  2.17614e-06|  0.00%|        self._collate_fn = loader.collate_fn
   497|      9060|    0.0272191|  3.00431e-06|  0.00%|        self._sampler_iter = iter(self._index_sampler)
   498|      9060|     0.193059|   2.1309e-05|  0.01%|        self._base_seed = torch.empty((), dtype=torch.int64).random_(generator=loader.generator).item()
   499|      9060|    0.0223026|  2.46166e-06|  0.00%|        self._persistent_workers = loader.persistent_workers
   500|      9060|    0.0193808|  2.13916e-06|  0.00%|        self._num_yielded = 0
   501|      9060|    0.0347345|  3.83383e-06|  0.00%|        self._profile_name = "enumerate(DataLoader)#{}.__next__".format(self.__cl
   510|         0|            0|            0|  0.00%|
   511|     76830|     0.106318|  1.38381e-06|  0.00%|    def _next_index(self):
   512|     76830|     0.450024|   5.8574e-06|  0.02%|        return next(self._sampler_iter)  # may raise StopIteration
(call)|     76830|      47.1971|  0.000614306|  2.06%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/sampler.py:224 __iter__
   513|         0|            0|            0|  0.00%|
   514|         0|            0|            0|  0.00%|    def _next_data(self):
   515|         0|            0|            0|  0.00%|        raise NotImplementedError
   516|         0|            0|            0|  0.00%|
   517|     76830|     0.183353|  2.38648e-06|  0.01%|    def __next__(self) -> Any:
   518|     76830|      0.92892|  1.20906e-05|  0.04%|        with torch.autograd.profiler.record_function(self._profile_name):
(call)|     76830|      1.02385|  1.33262e-05|  0.04%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/autograd/profiler.py:605 __init__
(call)|     76830|      1.02794|  1.33794e-05|  0.04%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/autograd/profiler.py:613 __enter__
   519|     76830|     0.191287|  2.48975e-06|  0.01%|            if self._sampler_iter is None:
   520|         0|            0|            0|  0.00%|                self._reset()
   521|     76830|     0.494298|  6.43366e-06|  0.02%|            data = self._next_data()
(call)|     76830|      1670.17|    0.0217386| 73.05%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:559 _next_data
   522|     76830|     0.206251|  2.68451e-06|  0.01%|            self._num_yielded += 1
   523|     76830|     0.152427|  1.98395e-06|  0.01%|            if self._dataset_kind == _DatasetKind.Iterable and \
   524|         0|            0|            0|  0.00%|                    self._IterableDataset_len_called is not None and \
   525|         0|            0|            0|  0.00%|                    self._num_yielded > self._IterableDataset_len_called:
   526|         0|            0|            0|  0.00%|                warn_msg = ("Length of IterableDataset {} was reported to be {} (when accessing len(dataloader)), but {} "
   527|         0|            0|            0|  0.00%|                            "samples have been fetched. ").format(self._dataset, self._IterableDataset_len_called,
   528|         0|            0|            0|  0.00%|                                                                  self._num_yielded)
   529|         0|            0|            0|  0.00%|                if self._num_workers > 0:
   530|         0|            0|            0|  0.00%|                    warn_msg += ("For multiprocessing data-loading, this could be caused by not properly configuring the "
   531|         0|            0|            0|  0.00%|                                 "IterableDataset replica at each worker. Please see "
   532|         0|            0|            0|  0.00%|                                 "https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.")
   533|         0|            0|            0|  0.00%|                warnings.warn(warn_msg)
   534|     76830|     0.521378|  6.78612e-06|  0.02%|            return data
(call)|     76830|     0.900705|  1.17234e-05|  0.04%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/autograd/profiler.py:617 __exit__
   535|         0|            0|            0|  0.00%|
   548|         0|            0|            0|  0.00%|
   549|         0|            0|            0|  0.00%|
   550|         0|            0|            0|  0.00%|class _SingleProcessDataLoaderIter(_BaseDataLoaderIter):
   551|      9060|    0.0175838|  1.94082e-06|  0.00%|    def __init__(self, loader):
   552|      9060|    0.0735486|  8.11794e-06|  0.00%|        super(_SingleProcessDataLoaderIter, self).__init__(loader)
(call)|      9060|     0.742019|  8.19005e-05|  0.03%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:485 __init__
   553|      9060|    0.0193865|  2.13979e-06|  0.00%|        assert self._timeout == 0
   554|      9060|    0.0177939|  1.96401e-06|  0.00%|        assert self._num_workers == 0
   555|         0|            0|            0|  0.00%|
   556|     18120|    0.0850999|  4.69646e-06|  0.00%|        self._dataset_fetcher = _DatasetKind.create_fetcher(
(call)|      9060|     0.281546|  3.10757e-05|  0.01%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:47 create_fetcher
   557|      9060|    0.0185714|  2.04982e-06|  0.00%|            self._dataset_kind, self._dataset, self._auto_collation, self._collate_fn, self._drop_last)
   558|         0|            0|            0|  0.00%|
   559|     76830|     0.137786|  1.79339e-06|  0.01%|    def _next_data(self):
   560|     76830|     0.441083|  5.74103e-06|  0.02%|        index = self._next_index()  # may raise StopIteration
(call)|     76830|      47.7535|  0.000621547|  2.09%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:511 _next_index
   561|     76830|      2.60425|  3.38963e-05|  0.11%|        data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
(call)|     76830|      1618.94|    0.0210718| 70.81%|# /home/liangsiqi/anaconda3/envs/s4l_torch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:42 fetch
   562|     76830|     0.175441|   2.2835e-06|  0.01%|        if self._pin_memory:
   563|         0|            0|            0|  0.00%|            data = _utils.pin_memory.pin_memory(data)
   564|     76830|     0.118011|    1.536e-06|  0.01%|        return data
   565|         0|            0|            0|  0.00%|
   566|         0|            0|            0|  0.00%|
   
